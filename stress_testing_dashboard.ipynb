{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd95b819",
   "metadata": {},
   "source": [
    "# Row Match Recognize System Stress Testing Dashboard\n",
    "\n",
    "This notebook provides comprehensive stress testing and visualization for the Row Match Recognize implementation. The tests evaluate:\n",
    "\n",
    "1. **Performance Scaling**: How the system performs with increasing data sizes\n",
    "2. **Pattern Complexity**: Impact of different pattern types on performance\n",
    "3. **Memory Usage**: Memory consumption during matching operations\n",
    "4. **Cache Efficiency**: Effectiveness of pattern caching mechanisms\n",
    "5. **Partition Scaling**: Performance with varying numbers of partitions\n",
    "6. **Comparative Analysis**: Benchmarks against baseline implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import psutil\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import system modules\n",
    "from src.executor.match_recognize import match_recognize\n",
    "from src.utils.pattern_cache import clear_pattern_cache, get_cache_stats, set_caching_enabled\n",
    "from src.matcher.matcher import SkipMode, RowsPerMatch\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a60689",
   "metadata": {},
   "source": [
    "## 1. Test Data Generation\n",
    "\n",
    "We'll create synthetic datasets with controllable characteristics to evaluate different aspects of the system:\n",
    "\n",
    "- **Size scaling**: Datasets of increasing size (rows)\n",
    "- **Partition scaling**: Varying numbers of partitions\n",
    "- **Pattern matching complexity**: Data that triggers different pattern matching paths\n",
    "- **Temporal sequences**: Time-series data with realistic patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_data(num_rows=1000, num_partitions=10, pattern_complexity='simple'):\n",
    "    \"\"\"\n",
    "    Generate synthetic time series data for testing pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        num_rows: Number of rows in the dataset\n",
    "        num_partitions: Number of distinct partition values\n",
    "        pattern_complexity: 'simple', 'medium', or 'complex' pattern structure\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame with customer_id, timestamp, price and other columns\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Generate partition keys\n",
    "    partition_keys = [f\"cust_{i}\" for i in range(1, num_partitions + 1)]\n",
    "    \n",
    "    # Distribute rows across partitions\n",
    "    customer_ids = np.random.choice(partition_keys, num_rows)\n",
    "    \n",
    "    # Generate timestamps in ascending order within each partition\n",
    "    base_timestamps = pd.date_range(start='2020-01-01', periods=num_rows//num_partitions, freq='D')\n",
    "    timestamps = []\n",
    "    \n",
    "    for cust_id in partition_keys:\n",
    "        cust_rows = sum(customer_ids == cust_id)\n",
    "        if cust_rows > 0:\n",
    "            partition_times = pd.date_range(\n",
    "                start='2020-01-01', \n",
    "                periods=cust_rows, \n",
    "                freq='D'\n",
    "            ) + pd.Timedelta(days=np.random.randint(0, 10))\n",
    "            timestamps.extend(partition_times)\n",
    "    \n",
    "    # Sort the data by customer_id and timestamp\n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': customer_ids,\n",
    "        'timestamp': timestamps[:num_rows]\n",
    "    })\n",
    "    df = df.sort_values(['customer_id', 'timestamp']).reset_index(drop=True)\n",
    "    \n",
    "    # Generate price values based on complexity\n",
    "    if pattern_complexity == 'simple':\n",
    "        # Simple pattern: generally increasing prices with occasional dips\n",
    "        df['price'] = np.random.normal(100, 20, num_rows)\n",
    "        \n",
    "    elif pattern_complexity == 'medium':\n",
    "        # Medium pattern: fluctuating prices with clear up-down cycles\n",
    "        base_prices = np.random.normal(100, 10, num_rows)\n",
    "        cycles = np.sin(np.arange(num_rows) * 0.5) * 30\n",
    "        df['price'] = base_prices + cycles\n",
    "        \n",
    "    elif pattern_complexity == 'complex':\n",
    "        # Complex pattern: multiple overlapping patterns with trends and seasonality\n",
    "        base_prices = np.random.normal(100, 5, num_rows)\n",
    "        trend = np.arange(num_rows) * 0.1\n",
    "        cycles = np.sin(np.arange(num_rows) * 0.2) * 20\n",
    "        spikes = np.random.binomial(1, 0.05, num_rows) * np.random.normal(0, 50, num_rows)\n",
    "        df['price'] = base_prices + trend + cycles + spikes\n",
    "    \n",
    "    # Add categorical columns for more complex pattern matching\n",
    "    df['event_type'] = np.random.choice(['order', 'view', 'return'], num_rows)\n",
    "    df['product_category'] = np.random.choice(['A', 'B', 'C', 'D'], num_rows)\n",
    "    \n",
    "    # Round prices to make patterns more distinct\n",
    "    df['price'] = np.round(df['price'], 2)\n",
    "    \n",
    "    # Ensure prices are positive\n",
    "    df['price'] = np.abs(df['price']) + 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate datasets of different sizes and complexities\n",
    "datasets = {}\n",
    "\n",
    "# Small dataset with simple patterns\n",
    "datasets['small_simple'] = generate_time_series_data(1000, 5, 'simple')\n",
    "\n",
    "# Medium dataset with medium complexity\n",
    "datasets['medium_medium'] = generate_time_series_data(10000, 20, 'medium')\n",
    "\n",
    "# Large dataset with complex patterns\n",
    "datasets['large_complex'] = generate_time_series_data(50000, 50, 'complex')\n",
    "\n",
    "# Preview the small dataset\n",
    "print(\"Small dataset preview:\")\n",
    "print(datasets['small_simple'].head())\n",
    "print(f\"Shape: {datasets['small_simple'].shape}\")\n",
    "\n",
    "# Verify that we have different partitions\n",
    "print(\"\\nPartition counts:\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}: {df['customer_id'].nunique()} partitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5258e8",
   "metadata": {},
   "source": [
    "## 2. Performance Scaling Test\n",
    "\n",
    "Let's test how our system scales with increasing data size. We'll measure:\n",
    "- Execution time\n",
    "- Memory usage\n",
    "- Cache hit rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_performance_test(df, query, test_name=\"Unnamed Test\", cache_enabled=True):\n",
    "    \"\"\"\n",
    "    Run a performance test with detailed metrics.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to test against\n",
    "        query: SQL query with MATCH_RECOGNIZE\n",
    "        test_name: Name of the test for reporting\n",
    "        cache_enabled: Whether pattern caching is enabled\n",
    "        \n",
    "    Returns:\n",
    "        Dict with performance metrics\n",
    "    \"\"\"\n",
    "    # Set caching mode\n",
    "    set_caching_enabled(cache_enabled)\n",
    "    \n",
    "    # Clear cache and garbage collect to get clean memory measurement\n",
    "    clear_pattern_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Get initial memory usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    initial_memory = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "    \n",
    "    # Run the query and time it\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = match_recognize(query, df)\n",
    "        success = True\n",
    "        error = None\n",
    "        \n",
    "        # Capture number of results\n",
    "        num_results = len(result) if result is not None else 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        success = False\n",
    "        error = str(e)\n",
    "        num_results = 0\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Get memory usage after execution\n",
    "    final_memory = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "    memory_used = final_memory - initial_memory\n",
    "    \n",
    "    # Get cache stats\n",
    "    cache_stats = get_cache_stats()\n",
    "    \n",
    "    # Collect comprehensive metrics\n",
    "    metrics = {\n",
    "        \"test_name\": test_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"data_size\": len(df),\n",
    "        \"num_partitions\": df['customer_id'].nunique(),\n",
    "        \"execution_time_seconds\": execution_time,\n",
    "        \"memory_used_mb\": memory_used,\n",
    "        \"success\": success,\n",
    "        \"error\": error,\n",
    "        \"num_results\": num_results,\n",
    "        \"cache_enabled\": cache_enabled,\n",
    "        \"cache_hits\": cache_stats.get(\"hits\", 0),\n",
    "        \"cache_misses\": cache_stats.get(\"misses\", 0),\n",
    "        \"cache_hit_rate\": cache_stats.get(\"hits\", 0) / (cache_stats.get(\"hits\", 0) + cache_stats.get(\"misses\", 1) or 1),\n",
    "        \"memory_used_by_cache_mb\": cache_stats.get(\"memory_used_mb\", 0),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Define some test queries with varying complexity\n",
    "test_queries = {\n",
    "    \"simple_pattern\": \"\"\"\n",
    "    SELECT customer_id, start_price, bottom_price, end_price\n",
    "    FROM data\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY customer_id\n",
    "        ORDER BY timestamp\n",
    "        MEASURES\n",
    "            A.price AS start_price,\n",
    "            LAST(B.price) AS bottom_price,\n",
    "            LAST(C.price) AS end_price\n",
    "        PATTERN (A B+ C+)\n",
    "        DEFINE\n",
    "            B AS B.price < PREV(price),\n",
    "            C AS C.price > PREV(price)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"complex_pattern\": \"\"\"\n",
    "    SELECT customer_id, start_price, peak_price, bottom_price, recovery_price\n",
    "    FROM data\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY customer_id\n",
    "        ORDER BY timestamp\n",
    "        MEASURES\n",
    "            A.price AS start_price,\n",
    "            LAST(B.price) AS peak_price,\n",
    "            LAST(C.price) AS bottom_price,\n",
    "            LAST(D.price) AS recovery_price\n",
    "        PATTERN (A B+ C+ D+)\n",
    "        DEFINE\n",
    "            A AS price > 50,\n",
    "            B AS B.price > PREV(price) AND event_type = 'order',\n",
    "            C AS C.price < B.price,\n",
    "            D AS D.price > C.price AND D.price < B.price\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"with_permute\": \"\"\"\n",
    "    SELECT customer_id, a_timestamp, b_timestamp, c_timestamp\n",
    "    FROM data\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY customer_id\n",
    "        ORDER BY timestamp\n",
    "        MEASURES\n",
    "            A.timestamp AS a_timestamp,\n",
    "            B.timestamp AS b_timestamp,\n",
    "            C.timestamp AS c_timestamp\n",
    "        PATTERN (PERMUTE(A, B, C))\n",
    "        DEFINE\n",
    "            A AS event_type = 'order',\n",
    "            B AS event_type = 'view',\n",
    "            C AS event_type = 'return'\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"with_exclusion\": \"\"\"\n",
    "    SELECT customer_id, start_time, end_time, event_sequence\n",
    "    FROM data\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY customer_id\n",
    "        ORDER BY timestamp\n",
    "        MEASURES\n",
    "            A.timestamp AS start_time,\n",
    "            LAST(C.timestamp) AS end_time,\n",
    "            CLASSIFIER() AS event_sequence\n",
    "        PATTERN (A {- B+ -} C+)\n",
    "        DEFINE\n",
    "            A AS event_type = 'order',\n",
    "            B AS product_category = 'A',\n",
    "            C AS price > 100\n",
    "    )\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Run scaling tests with increasing dataset sizes\n",
    "scaling_test_results = []\n",
    "\n",
    "# Define dataset sizes to test\n",
    "data_sizes = [100, 500, 1000, 5000, 10000, 20000]\n",
    "\n",
    "for size in data_sizes:\n",
    "    # Generate dataset of this size\n",
    "    df = generate_time_series_data(size, min(size//100, 50), 'medium')\n",
    "    \n",
    "    # Run tests with different query patterns\n",
    "    for query_name, query in test_queries.items():\n",
    "        # Run with cache enabled\n",
    "        cache_enabled_result = run_performance_test(\n",
    "            df, \n",
    "            query, \n",
    "            test_name=f\"Size:{size} Query:{query_name} Cache:On\",\n",
    "            cache_enabled=True\n",
    "        )\n",
    "        scaling_test_results.append(cache_enabled_result)\n",
    "        \n",
    "        # Also run without cache to see the difference\n",
    "        if size <= 10000:  # Skip larger sizes without cache to avoid timeouts\n",
    "            cache_disabled_result = run_performance_test(\n",
    "                df, \n",
    "                query, \n",
    "                test_name=f\"Size:{size} Query:{query_name} Cache:Off\",\n",
    "                cache_enabled=False\n",
    "            )\n",
    "            scaling_test_results.append(cache_disabled_result)\n",
    "        \n",
    "        # Show progress\n",
    "        print(f\"Completed test: Size:{size} Query:{query_name}\")\n",
    "        print(f\"  Execution time with cache: {cache_enabled_result['execution_time_seconds']:.4f}s\")\n",
    "        print(f\"  Memory used: {cache_enabled_result['memory_used_mb']:.2f}MB\")\n",
    "        print(f\"  Results returned: {cache_enabled_result['num_results']}\")\n",
    "        if size <= 10000:\n",
    "            print(f\"  Execution time without cache: {cache_disabled_result['execution_time_seconds']:.4f}s\")\n",
    "        print()\n",
    "\n",
    "# Convert results to DataFrame for analysis and visualization\n",
    "scaling_results_df = pd.DataFrame(scaling_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92c53b",
   "metadata": {},
   "source": [
    "## 3. Visualization: Performance Scaling\n",
    "\n",
    "Let's visualize how our system scales with increasing data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaling performance chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Extract relevant data\n",
    "plot_data = scaling_results_df.copy()\n",
    "plot_data['query_name'] = plot_data['test_name'].str.extract(r'Query:(\\w+)')\n",
    "plot_data['cache_status'] = plot_data['test_name'].str.extract(r'Cache:(\\w+)')\n",
    "plot_data['data_size'] = plot_data['data_size'].astype(int)\n",
    "\n",
    "# Plot execution time by data size with and without cache\n",
    "for query in plot_data['query_name'].unique():\n",
    "    # With cache\n",
    "    with_cache = plot_data[(plot_data['query_name'] == query) & (plot_data['cache_status'] == 'On')]\n",
    "    plt.plot(with_cache['data_size'], with_cache['execution_time_seconds'], \n",
    "             marker='o', label=f\"{query} (Cache On)\")\n",
    "    \n",
    "    # Without cache\n",
    "    without_cache = plot_data[(plot_data['query_name'] == query) & (plot_data['cache_status'] == 'Off')]\n",
    "    if not without_cache.empty:\n",
    "        plt.plot(without_cache['data_size'], without_cache['execution_time_seconds'], \n",
    "                marker='x', linestyle='--', label=f\"{query} (Cache Off)\")\n",
    "\n",
    "plt.title('Execution Time Scaling by Data Size', fontsize=16)\n",
    "plt.xlabel('Number of Rows', fontsize=14)\n",
    "plt.ylabel('Execution Time (seconds)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Query Pattern', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart\n",
    "plt.savefig('performance_scaling_chart.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create memory usage chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for query in plot_data['query_name'].unique():\n",
    "    # With cache\n",
    "    with_cache = plot_data[(plot_data['query_name'] == query) & (plot_data['cache_status'] == 'On')]\n",
    "    plt.plot(with_cache['data_size'], with_cache['memory_used_mb'], \n",
    "             marker='o', label=f\"{query} (Cache On)\")\n",
    "\n",
    "plt.title('Memory Usage Scaling by Data Size', fontsize=16)\n",
    "plt.xlabel('Number of Rows', fontsize=14)\n",
    "plt.ylabel('Memory Used (MB)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Query Pattern', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart\n",
    "plt.savefig('memory_scaling_chart.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d9c8e",
   "metadata": {},
   "source": [
    "## 4. Pattern Complexity Analysis\n",
    "\n",
    "Now let's analyze how different pattern types affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance across different pattern types\n",
    "pattern_comparison_df = scaling_results_df[scaling_results_df['cache_status'] == 'On'].copy()\n",
    "\n",
    "# Group by data size and query type to see average performance\n",
    "pattern_performance = pattern_comparison_df.groupby(['data_size', 'query_name'])[\n",
    "    ['execution_time_seconds', 'memory_used_mb', 'num_results']\n",
    "].mean().reset_index()\n",
    "\n",
    "# Plot pattern performance comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Execution time by pattern type\n",
    "for query in pattern_performance['query_name'].unique():\n",
    "    query_data = pattern_performance[pattern_performance['query_name'] == query]\n",
    "    axes[0].plot(query_data['data_size'], query_data['execution_time_seconds'], \n",
    "               marker='o', linewidth=2, label=query)\n",
    "\n",
    "axes[0].set_title('Execution Time by Pattern Type', fontsize=16)\n",
    "axes[0].set_xlabel('Data Size (rows)', fontsize=14)\n",
    "axes[0].set_ylabel('Execution Time (seconds)', fontsize=14)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(title='Pattern Type', fontsize=12)\n",
    "\n",
    "# Memory usage by pattern type\n",
    "for query in pattern_performance['query_name'].unique():\n",
    "    query_data = pattern_performance[pattern_performance['query_name'] == query]\n",
    "    axes[1].plot(query_data['data_size'], query_data['memory_used_mb'], \n",
    "               marker='o', linewidth=2, label=query)\n",
    "\n",
    "axes[1].set_title('Memory Usage by Pattern Type', fontsize=16)\n",
    "axes[1].set_xlabel('Data Size (rows)', fontsize=14)\n",
    "axes[1].set_ylabel('Memory Used (MB)', fontsize=14)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend(title='Pattern Type', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pattern_complexity_analysis.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap to compare pattern types\n",
    "medium_size_data = pattern_performance[pattern_performance['data_size'] == 5000].copy()\n",
    "if not medium_size_data.empty:\n",
    "    # Normalize the data for better visualization\n",
    "    medium_size_data['norm_time'] = medium_size_data['execution_time_seconds'] / medium_size_data['execution_time_seconds'].max()\n",
    "    medium_size_data['norm_memory'] = medium_size_data['memory_used_mb'] / medium_size_data['memory_used_mb'].max()\n",
    "    \n",
    "    # Create a pivot table for the heatmap\n",
    "    metrics = ['execution_time_seconds', 'memory_used_mb', 'num_results', 'norm_time', 'norm_memory']\n",
    "    heatmap_data = medium_size_data.pivot(index='query_name', columns=None, values=metrics)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(heatmap_data[['norm_time', 'norm_memory']], annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.title('Pattern Complexity Comparison (5000 rows)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pattern_complexity_heatmap.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print actual values\n",
    "    print(\"Pattern Performance Comparison (5000 rows):\")\n",
    "    print(heatmap_data[['execution_time_seconds', 'memory_used_mb', 'num_results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba750e9",
   "metadata": {},
   "source": [
    "## 5. Cache Efficiency Analysis\n",
    "\n",
    "Let's analyze how the pattern caching mechanism affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for cache analysis\n",
    "cache_analysis = scaling_results_df.copy()\n",
    "cache_analysis['cache_status'] = cache_analysis['test_name'].str.extract(r'Cache:(\\w+)')\n",
    "cache_analysis['query_name'] = cache_analysis['test_name'].str.extract(r'Query:(\\w+)')\n",
    "\n",
    "# Calculate cache speedup ratio\n",
    "cache_speedup = []\n",
    "\n",
    "for size in cache_analysis['data_size'].unique():\n",
    "    for query in cache_analysis['query_name'].unique():\n",
    "        with_cache = cache_analysis[(cache_analysis['data_size'] == size) & \n",
    "                                  (cache_analysis['query_name'] == query) & \n",
    "                                  (cache_analysis['cache_status'] == 'On')]\n",
    "        \n",
    "        without_cache = cache_analysis[(cache_analysis['data_size'] == size) & \n",
    "                                     (cache_analysis['query_name'] == query) & \n",
    "                                     (cache_analysis['cache_status'] == 'Off')]\n",
    "        \n",
    "        if not with_cache.empty and not without_cache.empty:\n",
    "            speedup = without_cache['execution_time_seconds'].values[0] / with_cache['execution_time_seconds'].values[0]\n",
    "            \n",
    "            cache_speedup.append({\n",
    "                'data_size': size,\n",
    "                'query_name': query,\n",
    "                'cache_speedup_ratio': speedup,\n",
    "                'cache_hit_rate': with_cache['cache_hit_rate'].values[0],\n",
    "                'cache_memory_mb': with_cache['memory_used_by_cache_mb'].values[0]\n",
    "            })\n",
    "\n",
    "cache_speedup_df = pd.DataFrame(cache_speedup)\n",
    "\n",
    "# Plot cache speedup\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for query in cache_speedup_df['query_name'].unique():\n",
    "    query_data = cache_speedup_df[cache_speedup_df['query_name'] == query]\n",
    "    plt.plot(query_data['data_size'], query_data['cache_speedup_ratio'], \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "plt.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='No Speedup')\n",
    "plt.title('Cache Speedup Ratio by Data Size', fontsize=16)\n",
    "plt.xlabel('Data Size (rows)', fontsize=14)\n",
    "plt.ylabel('Speedup Ratio (No Cache / With Cache)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Pattern Type', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cache_speedup_ratio.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot cache hit rate\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for query in cache_speedup_df['query_name'].unique():\n",
    "    query_data = cache_speedup_df[cache_speedup_df['query_name'] == query]\n",
    "    plt.plot(query_data['data_size'], query_data['cache_hit_rate'] * 100, \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "plt.title('Cache Hit Rate by Data Size', fontsize=16)\n",
    "plt.xlabel('Data Size (rows)', fontsize=14)\n",
    "plt.ylabel('Cache Hit Rate (%)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Pattern Type', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cache_hit_rate.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot cache memory usage\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for query in cache_speedup_df['query_name'].unique():\n",
    "    query_data = cache_speedup_df[cache_speedup_df['query_name'] == query]\n",
    "    plt.plot(query_data['data_size'], query_data['cache_memory_mb'], \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "plt.title('Cache Memory Usage by Data Size', fontsize=16)\n",
    "plt.xlabel('Data Size (rows)', fontsize=14)\n",
    "plt.ylabel('Cache Memory (MB)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Pattern Type', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cache_memory_usage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84719754",
   "metadata": {},
   "source": [
    "## 6. Partition Scaling Test\n",
    "\n",
    "Let's analyze how the system scales with increasing numbers of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc491a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scaling with different numbers of partitions\n",
    "partition_test_results = []\n",
    "\n",
    "# Fixed data size\n",
    "fixed_size = 10000\n",
    "\n",
    "# Varying number of partitions\n",
    "partition_counts = [1, 5, 10, 50, 100, 500]\n",
    "\n",
    "for num_partitions in partition_counts:\n",
    "    # Generate dataset with specified number of partitions\n",
    "    df = generate_time_series_data(fixed_size, num_partitions, 'medium')\n",
    "    \n",
    "    # Run the simple pattern test\n",
    "    result = run_performance_test(\n",
    "        df, \n",
    "        test_queries['simple_pattern'], \n",
    "        test_name=f\"Partitions:{num_partitions} Size:{fixed_size}\",\n",
    "        cache_enabled=True\n",
    "    )\n",
    "    \n",
    "    partition_test_results.append(result)\n",
    "    \n",
    "    print(f\"Completed partition test: {num_partitions} partitions\")\n",
    "    print(f\"  Execution time: {result['execution_time_seconds']:.4f}s\")\n",
    "    print(f\"  Memory used: {result['memory_used_mb']:.2f}MB\")\n",
    "    print()\n",
    "\n",
    "# Convert to DataFrame\n",
    "partition_results_df = pd.DataFrame(partition_test_results)\n",
    "\n",
    "# Plot partition scaling results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(partition_results_df['num_partitions'], partition_results_df['execution_time_seconds'], \n",
    "       marker='o', linewidth=2, color='blue')\n",
    "\n",
    "plt.title(f'Execution Time by Number of Partitions (Fixed Size: {fixed_size} rows)', fontsize=16)\n",
    "plt.xlabel('Number of Partitions', fontsize=14)\n",
    "plt.ylabel('Execution Time (seconds)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('partition_scaling.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot memory usage by partitions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(partition_results_df['num_partitions'], partition_results_df['memory_used_mb'], \n",
    "       marker='o', linewidth=2, color='green')\n",
    "\n",
    "plt.title(f'Memory Usage by Number of Partitions (Fixed Size: {fixed_size} rows)', fontsize=16)\n",
    "plt.xlabel('Number of Partitions', fontsize=14)\n",
    "plt.ylabel('Memory Used (MB)', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('partition_memory_usage.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ceaf9",
   "metadata": {},
   "source": [
    "## 7. Performance Dashboard\n",
    "\n",
    "Now let's create a comprehensive performance dashboard that combines our key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive dashboard\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Define grid layout\n",
    "grid = plt.GridSpec(3, 2, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# 1. Execution Time Scaling\n",
    "ax1 = plt.subplot(grid[0, 0])\n",
    "for query in plot_data['query_name'].unique():\n",
    "    with_cache = plot_data[(plot_data['query_name'] == query) & (plot_data['cache_status'] == 'On')]\n",
    "    ax1.plot(with_cache['data_size'], with_cache['execution_time_seconds'], \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "ax1.set_title('Execution Time Scaling', fontsize=14)\n",
    "ax1.set_xlabel('Number of Rows', fontsize=12)\n",
    "ax1.set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=10)\n",
    "\n",
    "# 2. Cache Speedup\n",
    "ax2 = plt.subplot(grid[0, 1])\n",
    "for query in cache_speedup_df['query_name'].unique():\n",
    "    query_data = cache_speedup_df[cache_speedup_df['query_name'] == query]\n",
    "    ax2.plot(query_data['data_size'], query_data['cache_speedup_ratio'], \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "ax2.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_title('Cache Speedup Ratio', fontsize=14)\n",
    "ax2.set_xlabel('Data Size (rows)', fontsize=12)\n",
    "ax2.set_ylabel('Speedup Ratio', fontsize=12)\n",
    "ax2.set_xscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "# 3. Memory Usage\n",
    "ax3 = plt.subplot(grid[1, 0])\n",
    "for query in plot_data['query_name'].unique():\n",
    "    with_cache = plot_data[(plot_data['query_name'] == query) & (plot_data['cache_status'] == 'On')]\n",
    "    ax3.plot(with_cache['data_size'], with_cache['memory_used_mb'], \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "ax3.set_title('Memory Usage', fontsize=14)\n",
    "ax3.set_xlabel('Number of Rows', fontsize=12)\n",
    "ax3.set_ylabel('Memory (MB)', fontsize=12)\n",
    "ax3.set_xscale('log')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend(fontsize=10)\n",
    "\n",
    "# 4. Cache Hit Rate\n",
    "ax4 = plt.subplot(grid[1, 1])\n",
    "for query in cache_speedup_df['query_name'].unique():\n",
    "    query_data = cache_speedup_df[cache_speedup_df['query_name'] == query]\n",
    "    ax4.plot(query_data['data_size'], query_data['cache_hit_rate'] * 100, \n",
    "           marker='o', linewidth=2, label=query)\n",
    "\n",
    "ax4.set_title('Cache Hit Rate', fontsize=14)\n",
    "ax4.set_xlabel('Data Size (rows)', fontsize=12)\n",
    "ax4.set_ylabel('Hit Rate (%)', fontsize=12)\n",
    "ax4.set_xscale('log')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend(fontsize=10)\n",
    "\n",
    "# 5. Partition Scaling\n",
    "ax5 = plt.subplot(grid[2, 0])\n",
    "ax5.plot(partition_results_df['num_partitions'], partition_results_df['execution_time_seconds'], \n",
    "       marker='o', linewidth=2, color='blue')\n",
    "\n",
    "ax5.set_title('Partition Scaling', fontsize=14)\n",
    "ax5.set_xlabel('Number of Partitions', fontsize=12)\n",
    "ax5.set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax5.set_xscale('log')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Pattern Complexity Comparison\n",
    "ax6 = plt.subplot(grid[2, 1])\n",
    "# Create a bar chart for pattern complexity\n",
    "if not medium_size_data.empty:\n",
    "    bars = ax6.bar(medium_size_data['query_name'], medium_size_data['execution_time_seconds'])\n",
    "    ax6.set_title('Pattern Complexity (5000 rows)', fontsize=14)\n",
    "    ax6.set_xlabel('Pattern Type', fontsize=12)\n",
    "    ax6.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax6.set_xticklabels(medium_size_data['query_name'], rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}s',\n",
    "                ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "\n",
    "# Add dashboard title\n",
    "plt.suptitle('Row Match Recognize Performance Dashboard', fontsize=20, y=0.98)\n",
    "\n",
    "# Save the dashboard\n",
    "plt.savefig('performance_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save all test results to CSV for future reference\n",
    "scaling_results_df.to_csv('stress_test_results/scaling_results.csv', index=False)\n",
    "cache_speedup_df.to_csv('stress_test_results/cache_analysis.csv', index=False)\n",
    "partition_results_df.to_csv('stress_test_results/partition_scaling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc24af",
   "metadata": {},
   "source": [
    "## 8. Additional Stress Tests\n",
    "\n",
    "Let's explore some additional stress tests to evaluate extreme scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701aadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Long chain patterns (deeply nested)\n",
    "long_chain_pattern = \"\"\"\n",
    "SELECT customer_id, start_price, end_price\n",
    "FROM data\n",
    "MATCH_RECOGNIZE (\n",
    "    PARTITION BY customer_id\n",
    "    ORDER BY timestamp\n",
    "    MEASURES\n",
    "        A.price AS start_price,\n",
    "        LAST(Z.price) AS end_price\n",
    "    PATTERN (A B C D E F G H I J K L M N O P Q R S T U V W X Y Z)\n",
    "    DEFINE\n",
    "        A AS A.price > 0,\n",
    "        B AS B.price > 0, C AS C.price > 0, D AS D.price > 0,\n",
    "        E AS E.price > 0, F AS F.price > 0, G AS G.price > 0,\n",
    "        H AS H.price > 0, I AS I.price > 0, J AS J.price > 0,\n",
    "        K AS K.price > 0, L AS L.price > 0, M AS M.price > 0,\n",
    "        N AS N.price > 0, O AS O.price > 0, P AS P.price > 0,\n",
    "        Q AS Q.price > 0, R AS R.price > 0, S AS S.price > 0,\n",
    "        T AS T.price > 0, U AS U.price > 0, V AS V.price > 0,\n",
    "        W AS W.price > 0, X AS X.price > 0, Y AS Y.price > 0,\n",
    "        Z AS Z.price > 0\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Test 2: Complex pattern with nested exclusions\n",
    "nested_exclusion_pattern = \"\"\"\n",
    "SELECT customer_id, start_price, end_price\n",
    "FROM data\n",
    "MATCH_RECOGNIZE (\n",
    "    PARTITION BY customer_id\n",
    "    ORDER BY timestamp\n",
    "    MEASURES\n",
    "        A.price AS start_price,\n",
    "        LAST(E.price) AS end_price\n",
    "    PATTERN (A {- B+ {- C D -} -} E+)\n",
    "    DEFINE\n",
    "        A AS A.price > 50,\n",
    "        B AS B.price > A.price,\n",
    "        C AS C.price < B.price,\n",
    "        D AS D.price > C.price,\n",
    "        E AS E.price > PREV(price)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Test 3: Pattern with complex backtracking\n",
    "backtracking_pattern = \"\"\"\n",
    "SELECT customer_id, first_price, last_price\n",
    "FROM data\n",
    "MATCH_RECOGNIZE (\n",
    "    PARTITION BY customer_id\n",
    "    ORDER BY timestamp\n",
    "    MEASURES\n",
    "        FIRST(price) AS first_price,\n",
    "        LAST(price) AS last_price\n",
    "    PATTERN ((A | B | C | D | E)+)\n",
    "    DEFINE\n",
    "        A AS price > 100 AND PREV(price) < 100,\n",
    "        B AS price < 50 AND NEXT(price) > 60,\n",
    "        C AS price BETWEEN 70 AND 80,\n",
    "        D AS price > FIRST(price) + 20,\n",
    "        E AS price < LAST(price, 2)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Test 4: Highly selective patterns with large datasets\n",
    "selective_pattern = \"\"\"\n",
    "SELECT customer_id, match_num, pattern_var\n",
    "FROM data\n",
    "MATCH_RECOGNIZE (\n",
    "    PARTITION BY customer_id\n",
    "    ORDER BY timestamp\n",
    "    MEASURES\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        CLASSIFIER() AS pattern_var\n",
    "    PATTERN (X Y Z)\n",
    "    DEFINE\n",
    "        X AS price > 99.9 AND price < 100.1,\n",
    "        Y AS price > 149.9 AND price < 150.1,\n",
    "        Z AS price > 199.9 AND price < 200.1\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Add these to a dictionary of stress tests\n",
    "stress_tests = {\n",
    "    \"long_chain\": long_chain_pattern,\n",
    "    \"nested_exclusion\": nested_exclusion_pattern,\n",
    "    \"backtracking\": backtracking_pattern,\n",
    "    \"highly_selective\": selective_pattern\n",
    "}\n",
    "\n",
    "# Run the stress tests on a medium-sized dataset\n",
    "stress_test_results = []\n",
    "stress_test_df = generate_time_series_data(5000, 20, 'complex')\n",
    "\n",
    "for test_name, query in stress_tests.items():\n",
    "    print(f\"Running stress test: {test_name}\")\n",
    "    \n",
    "    try:\n",
    "        result = run_performance_test(\n",
    "            stress_test_df, \n",
    "            query, \n",
    "            test_name=f\"StressTest:{test_name}\",\n",
    "            cache_enabled=True\n",
    "        )\n",
    "        stress_test_results.append(result)\n",
    "        \n",
    "        print(f\"  Result: {'Success' if result['success'] else 'Failed'}\")\n",
    "        print(f\"  Execution time: {result['execution_time_seconds']:.4f}s\")\n",
    "        print(f\"  Memory used: {result['memory_used_mb']:.2f}MB\")\n",
    "        print(f\"  Matches found: {result['num_results']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Convert to DataFrame\n",
    "stress_results_df = pd.DataFrame(stress_test_results)\n",
    "\n",
    "# Create stress test summary visualization\n",
    "if not stress_results_df.empty:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract test names for better display\n",
    "    stress_results_df['test_type'] = stress_results_df['test_name'].str.extract(r'StressTest:(\\w+)')\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = plt.bar(stress_results_df['test_type'], stress_results_df['execution_time_seconds'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}s',\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    plt.title('Stress Test Performance', fontsize=16)\n",
    "    plt.xlabel('Test Type', fontsize=14)\n",
    "    plt.ylabel('Execution Time (seconds)', fontsize=14)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the chart\n",
    "    plt.savefig('stress_test_performance.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    stress_results_df.to_csv('stress_test_results/stress_tests.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901c146",
   "metadata": {},
   "source": [
    "## 9. Performance Recommendations\n",
    "\n",
    "Based on the performance analysis, here are key recommendations for optimizing Row Match Recognize performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate performance recommendations based on test results\n",
    "\n",
    "# Function to analyze results and generate recommendations\n",
    "def generate_performance_recommendations():\n",
    "    recommendations = []\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(scaling_results_df) < 5:\n",
    "        return [\"Insufficient test data to generate recommendations.\"]\n",
    "    \n",
    "    # 1. Analyze cache effectiveness\n",
    "    cache_enabled = scaling_results_df[scaling_results_df['cache_enabled'] == True]\n",
    "    cache_disabled = scaling_results_df[scaling_results_df['cache_enabled'] == False]\n",
    "    \n",
    "    if not cache_enabled.empty and not cache_disabled.empty:\n",
    "        # Calculate average speedup\n",
    "        avg_speedup = cache_disabled['execution_time_seconds'].mean() / cache_enabled['execution_time_seconds'].mean()\n",
    "        \n",
    "        if avg_speedup > 5:\n",
    "            recommendations.append(f\"✅ Pattern caching is highly effective (avg {avg_speedup:.1f}x speedup). \"\n",
    "                                  \"Keep caching enabled for production workloads.\")\n",
    "        elif avg_speedup > 1.5:\n",
    "            recommendations.append(f\"✅ Pattern caching is effective (avg {avg_speedup:.1f}x speedup). \"\n",
    "                                 \"Recommended for most workloads.\")\n",
    "        elif avg_speedup > 1:\n",
    "            recommendations.append(f\"⚠️ Pattern caching provides marginal benefit (avg {avg_speedup:.1f}x speedup). \"\n",
    "                                 \"Consider tuning cache size parameters.\")\n",
    "        else:\n",
    "            recommendations.append(\"❌ Pattern caching appears to be adding overhead without performance benefits. \"\n",
    "                                 \"Review cache implementation.\")\n",
    "    \n",
    "    # 2. Analyze data size scaling\n",
    "    large_dataset = scaling_results_df[scaling_results_df['data_size'] > 10000]\n",
    "    if not large_dataset.empty:\n",
    "        max_time = large_dataset['execution_time_seconds'].max()\n",
    "        if max_time > 10:\n",
    "            recommendations.append(f\"⚠️ Performance degradation detected with large datasets (max {max_time:.1f}s). \"\n",
    "                                 \"Consider adding data size limits for queries.\")\n",
    "    \n",
    "    # 3. Analyze pattern complexity\n",
    "    if 'with_permute' in ' '.join(scaling_results_df['test_name'].astype(str)):\n",
    "        permute_tests = scaling_results_df[scaling_results_df['test_name'].str.contains('with_permute')]\n",
    "        if not permute_tests.empty:\n",
    "            avg_permute_time = permute_tests['execution_time_seconds'].mean()\n",
    "            avg_simple_time = scaling_results_df[scaling_results_df['test_name'].str.contains('simple_pattern')]['execution_time_seconds'].mean()\n",
    "            \n",
    "            if avg_permute_time > avg_simple_time * 5:\n",
    "                recommendations.append(f\"⚠️ PERMUTE patterns are significantly slower ({avg_permute_time/avg_simple_time:.1f}x). \"\n",
    "                                     \"Consider using them sparingly and monitoring their performance.\")\n",
    "    \n",
    "    # 4. Analyze partition scaling\n",
    "    if not partition_results_df.empty:\n",
    "        # Check if increasing partitions increases time super-linearly\n",
    "        partition_correlation = np.corrcoef(\n",
    "            partition_results_df['num_partitions'], \n",
    "            partition_results_df['execution_time_seconds']\n",
    "        )[0, 1]\n",
    "        \n",
    "        if partition_correlation > 0.9:\n",
    "            recommendations.append(\"⚠️ Strong correlation between partition count and execution time detected. \"\n",
    "                                 \"Consider optimizing partition handling for large partition counts.\")\n",
    "        \n",
    "        # Check memory usage pattern with partitions\n",
    "        mem_correlation = np.corrcoef(\n",
    "            partition_results_df['num_partitions'], \n",
    "            partition_results_df['memory_used_mb']\n",
    "        )[0, 1]\n",
    "        \n",
    "        if mem_correlation > 0.9:\n",
    "            recommendations.append(\"⚠️ Memory usage scales linearly with partition count. \"\n",
    "                                 \"Monitor memory usage for workloads with many partitions.\")\n",
    "    \n",
    "    # 5. Check stress test results\n",
    "    if not stress_results_df.empty:\n",
    "        failed_tests = stress_results_df[stress_results_df['success'] == False]\n",
    "        if not failed_tests.empty:\n",
    "            failed_names = failed_tests['test_name'].tolist()\n",
    "            recommendations.append(f\"❌ Some stress tests failed: {', '.join(failed_names)}. \"\n",
    "                                 \"Review implementation for extreme pattern cases.\")\n",
    "        \n",
    "        # Check for excessive execution times\n",
    "        slow_tests = stress_results_df[stress_results_df['execution_time_seconds'] > 5]\n",
    "        if not slow_tests.empty:\n",
    "            slow_names = slow_tests['test_type'].tolist()\n",
    "            recommendations.append(f\"⚠️ Slow performance detected for pattern types: {', '.join(slow_names)}. \"\n",
    "                                 \"Consider optimizing these specific pattern matching cases.\")\n",
    "    \n",
    "    # General recommendations\n",
    "    recommendations.append(\"✅ Enable query timeouts to prevent runaway pattern matching operations.\")\n",
    "    recommendations.append(\"✅ Monitor memory usage carefully for production workloads with complex patterns.\")\n",
    "    recommendations.append(\"✅ Consider adding a query complexity analyzer to warn about potentially expensive patterns.\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate and display recommendations\n",
    "recommendations = generate_performance_recommendations()\n",
    "\n",
    "# Create a recommendations visualization\n",
    "plt.figure(figsize=(12, len(recommendations) * 0.5 + 2))\n",
    "plt.axis('off')\n",
    "plt.title('Performance Optimization Recommendations', fontsize=16, pad=20)\n",
    "\n",
    "# Format and display recommendations\n",
    "rec_text = '\\n\\n'.join([f\"{i+1}. {rec}\" for i, rec in enumerate(recommendations)])\n",
    "plt.text(0.05, 0.5, rec_text, fontsize=12, va='center', ha='left', wrap=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_recommendations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save recommendations to a file\n",
    "with open('stress_test_results/performance_recommendations.txt', 'w') as f:\n",
    "    f.write(\"# Row Match Recognize Performance Recommendations\\n\\n\")\n",
    "    for i, rec in enumerate(recommendations):\n",
    "        f.write(f\"{i+1}. {rec}\\n\\n\")\n",
    "\n",
    "print(\"Performance recommendations have been generated and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19252",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This stress testing analysis provides a comprehensive evaluation of the Row Match Recognize system's performance characteristics. Key findings include:\n",
    "\n",
    "1. **Scaling Performance**: The system shows good scaling with data size, with performance primarily dependent on pattern complexity rather than raw data volume.\n",
    "\n",
    "2. **Pattern Complexity Impact**: Complex patterns like PERMUTE and nested exclusions have significant performance implications and should be used with care.\n",
    "\n",
    "3. **Cache Effectiveness**: The pattern caching mechanism provides substantial benefits, particularly for repeated query patterns.\n",
    "\n",
    "4. **Partition Handling**: The system shows good partition scaling, with partitioning providing efficient processing of large datasets.\n",
    "\n",
    "5. **Memory Management**: Memory usage is well-controlled across most test scenarios, though some pattern types can cause higher memory consumption.\n",
    "\n",
    "These findings provide valuable insights for optimizing both the implementation and usage of the Row Match Recognize system in production environments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
