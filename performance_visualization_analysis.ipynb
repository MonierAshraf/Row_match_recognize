{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a334a6",
   "metadata": {},
   "source": [
    "# Comprehensive Performance Analysis: LRU vs FIFO vs No-Caching\n",
    "\n",
    "This notebook provides detailed performance comparison visualizations for the Row Match Recognize system caching strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb021d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for professional plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bb9e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 9 benchmark records\n",
      "\n",
      "üìã Data Summary:\n",
      "   ‚Ä¢ Total records: 9\n",
      "   ‚Ä¢ Cache modes: none, fifo, lru\n",
      "   ‚Ä¢ Scenarios: 3\n",
      "\n",
      "üîç Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cache_mode</th>\n",
       "      <th>avg_execution_time</th>\n",
       "      <th>first_run_time</th>\n",
       "      <th>subsequent_avg_time</th>\n",
       "      <th>execution_times</th>\n",
       "      <th>initial_memory</th>\n",
       "      <th>max_memory</th>\n",
       "      <th>memory_increase</th>\n",
       "      <th>memory_usages</th>\n",
       "      <th>cache_hits</th>\n",
       "      <th>cache_misses</th>\n",
       "      <th>cache_hit_rate</th>\n",
       "      <th>result_size</th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>scenario_description</th>\n",
       "      <th>complexity</th>\n",
       "      <th>pattern_type</th>\n",
       "      <th>data_size</th>\n",
       "      <th>execution_times_parsed</th>\n",
       "      <th>memory_usages_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>1.416025</td>\n",
       "      <td>1.392092</td>\n",
       "      <td>1.422009</td>\n",
       "      <td>[1.392092227935791, 1.4315712451934814, 1.4348...</td>\n",
       "      <td>229.402344</td>\n",
       "      <td>232.605469</td>\n",
       "      <td>3.203125</td>\n",
       "      <td>[229.40234375, 232.60546875, 232.60546875, 232...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Basic patterns, small dataset</td>\n",
       "      <td>simple</td>\n",
       "      <td>basic</td>\n",
       "      <td>1000</td>\n",
       "      <td>[1.392092227935791, 1.4315712451934814, 1.4348...</td>\n",
       "      <td>[229.40234375, 232.60546875, 232.60546875, 232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fifo</td>\n",
       "      <td>1.468439</td>\n",
       "      <td>1.617169</td>\n",
       "      <td>1.431256</td>\n",
       "      <td>[1.6171691417694092, 1.3491580486297607, 1.402...</td>\n",
       "      <td>232.605469</td>\n",
       "      <td>232.605469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[232.60546875, 232.60546875, 232.60546875, 232...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Basic patterns, small dataset</td>\n",
       "      <td>simple</td>\n",
       "      <td>basic</td>\n",
       "      <td>1000</td>\n",
       "      <td>[1.6171691417694092, 1.3491580486297607, 1.402...</td>\n",
       "      <td>[232.60546875, 232.60546875, 232.60546875, 232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lru</td>\n",
       "      <td>1.444003</td>\n",
       "      <td>1.517629</td>\n",
       "      <td>1.425597</td>\n",
       "      <td>[1.5176293849945068, 1.379716396331787, 1.5605...</td>\n",
       "      <td>232.605469</td>\n",
       "      <td>232.605469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[232.60546875, 232.60546875, 232.60546875, 232...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Basic patterns, small dataset</td>\n",
       "      <td>simple</td>\n",
       "      <td>basic</td>\n",
       "      <td>1000</td>\n",
       "      <td>[1.5176293849945068, 1.379716396331787, 1.5605...</td>\n",
       "      <td>[232.60546875, 232.60546875, 232.60546875, 232...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cache_mode  avg_execution_time  first_run_time  subsequent_avg_time  \\\n",
       "0       none            1.416025        1.392092             1.422009   \n",
       "1       fifo            1.468439        1.617169             1.431256   \n",
       "2        lru            1.444003        1.517629             1.425597   \n",
       "\n",
       "                                     execution_times  initial_memory  \\\n",
       "0  [1.392092227935791, 1.4315712451934814, 1.4348...      229.402344   \n",
       "1  [1.6171691417694092, 1.3491580486297607, 1.402...      232.605469   \n",
       "2  [1.5176293849945068, 1.379716396331787, 1.5605...      232.605469   \n",
       "\n",
       "   max_memory  memory_increase  \\\n",
       "0  232.605469         3.203125   \n",
       "1  232.605469         0.000000   \n",
       "2  232.605469         0.000000   \n",
       "\n",
       "                                       memory_usages  cache_hits  \\\n",
       "0  [229.40234375, 232.60546875, 232.60546875, 232...           0   \n",
       "1  [232.60546875, 232.60546875, 232.60546875, 232...          10   \n",
       "2  [232.60546875, 232.60546875, 232.60546875, 232...          10   \n",
       "\n",
       "   cache_misses  cache_hit_rate  result_size  scenario_id  \\\n",
       "0             5        0.000000            0            1   \n",
       "1             1       90.909091            0            1   \n",
       "2             1       90.909091            0            1   \n",
       "\n",
       "            scenario_description complexity pattern_type  data_size  \\\n",
       "0  Basic patterns, small dataset     simple        basic       1000   \n",
       "1  Basic patterns, small dataset     simple        basic       1000   \n",
       "2  Basic patterns, small dataset     simple        basic       1000   \n",
       "\n",
       "                              execution_times_parsed  \\\n",
       "0  [1.392092227935791, 1.4315712451934814, 1.4348...   \n",
       "1  [1.6171691417694092, 1.3491580486297607, 1.402...   \n",
       "2  [1.5176293849945068, 1.379716396331787, 1.5605...   \n",
       "\n",
       "                                memory_usages_parsed  \n",
       "0  [229.40234375, 232.60546875, 232.60546875, 232...  \n",
       "1  [232.60546875, 232.60546875, 232.60546875, 232...  \n",
       "2  [232.60546875, 232.60546875, 232.60546875, 232...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and process benchmark data\n",
    "def load_benchmark_data():\n",
    "    \"\"\"Load and process benchmark results\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('enhanced_benchmark_results.csv')\n",
    "        print(f\"‚úÖ Loaded {len(df)} benchmark records\")\n",
    "        \n",
    "        # Parse execution_times from string to list\n",
    "        def safe_parse_list(x):\n",
    "            try:\n",
    "                if isinstance(x, str):\n",
    "                    return ast.literal_eval(x)\n",
    "                return x\n",
    "            except:\n",
    "                return []\n",
    "        \n",
    "        df['execution_times_parsed'] = df['execution_times'].apply(safe_parse_list)\n",
    "        df['memory_usages_parsed'] = df['memory_usages'].apply(safe_parse_list)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "df = load_benchmark_data()\n",
    "if df is not None:\n",
    "    print(f\"\\nüìã Data Summary:\")\n",
    "    print(f\"   ‚Ä¢ Total records: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ Cache modes: {', '.join(df['cache_mode'].unique())}\")\n",
    "    print(f\"   ‚Ä¢ Scenarios: {len(df['scenario_description'].unique())}\")\n",
    "    print(f\"\\nüîç Sample data:\")\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719fc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Performance dashboard created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Performance Overview Dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üöÄ Performance Comparison Dashboard: LRU vs FIFO vs No-Caching', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# 1. Average Execution Time by Cache Mode\n",
    "ax1 = axes[0, 0]\n",
    "execution_comparison = df.groupby('cache_mode')['avg_execution_time'].mean().reset_index()\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "bars = ax1.bar(execution_comparison['cache_mode'], execution_comparison['avg_execution_time'], \n",
    "               color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "ax1.set_title('‚è±Ô∏è Average Execution Time by Cache Mode', fontweight='bold', pad=15)\n",
    "ax1.set_ylabel('Execution Time (seconds)')\n",
    "ax1.set_xlabel('Cache Mode')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "            f'{height:.3f}s', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 2. Cache Hit Rate Comparison\n",
    "ax2 = axes[0, 1]\n",
    "cache_data = df[df['cache_mode'] != 'none']\n",
    "if len(cache_data) > 0:\n",
    "    hit_rate_comparison = cache_data.groupby('cache_mode')['cache_hit_rate'].mean()\n",
    "    bars2 = ax2.bar(hit_rate_comparison.index, hit_rate_comparison.values, \n",
    "                   color=['#4ECDC4', '#45B7D1'], alpha=0.8, edgecolor='white', linewidth=2)\n",
    "    ax2.set_title('üéØ Cache Hit Rate Comparison', fontweight='bold', pad=15)\n",
    "    ax2.set_ylabel('Hit Rate (%)')\n",
    "    ax2.set_xlabel('Cache Mode')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 3. Memory Usage Comparison\n",
    "ax3 = axes[1, 0]\n",
    "memory_comparison = df.groupby('cache_mode')['memory_increase'].mean().reset_index()\n",
    "bars3 = ax3.bar(memory_comparison['cache_mode'], memory_comparison['memory_increase'], \n",
    "               color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "ax3.set_title('üíæ Average Memory Increase by Cache Mode', fontweight='bold', pad=15)\n",
    "ax3.set_ylabel('Memory Increase (MB)')\n",
    "ax3.set_xlabel('Cache Mode')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            f'{height:.2f}MB', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 4. Performance by Scenario Complexity\n",
    "ax4 = axes[1, 1]\n",
    "scenario_perf = df.groupby(['complexity', 'cache_mode'])['avg_execution_time'].mean().unstack()\n",
    "scenario_perf.plot(kind='bar', ax=ax4, color=colors, alpha=0.8, width=0.7)\n",
    "ax4.set_title('üìä Performance by Scenario Complexity', fontweight='bold', pad=15)\n",
    "ax4.set_ylabel('Execution Time (seconds)')\n",
    "ax4.set_xlabel('Complexity Level')\n",
    "ax4.legend(title='Cache Mode', framealpha=0.9)\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_comparison_dashboard.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Performance dashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857a2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Performance heatmap created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Detailed Performance Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = df.pivot_table(\n",
    "    values='avg_execution_time', \n",
    "    index='scenario_description', \n",
    "    columns='cache_mode', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Create heatmap with custom styling\n",
    "mask = heatmap_data.isnull()\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Execution Time (seconds)', 'shrink': 0.8},\n",
    "            linewidths=1, linecolor='white', square=False, mask=mask,\n",
    "            annot_kws={'fontsize': 12, 'fontweight': 'bold'})\n",
    "\n",
    "plt.title('üî• Performance Heatmap: Execution Time by Scenario and Cache Mode', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Cache Mode', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Test Scenario', fontweight='bold', fontsize=12)\n",
    "plt.xticks(rotation=0, fontsize=11)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_heatmap.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Performance heatmap created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35887b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scalability analysis created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Scalability Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "fig.suptitle('üìè Scalability Analysis: Performance vs Data Size', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "colors_dict = {'none': '#FF6B6B', 'fifo': '#4ECDC4', 'lru': '#45B7D1'}\n",
    "markers = {'none': 'o', 'fifo': 's', 'lru': '^'}\n",
    "\n",
    "# 1. Execution Time vs Data Size\n",
    "ax1 = axes[0]\n",
    "for cache_mode in df['cache_mode'].unique():\n",
    "    cache_data = df[df['cache_mode'] == cache_mode].sort_values('data_size')\n",
    "    ax1.plot(cache_data['data_size'], cache_data['avg_execution_time'], \n",
    "            marker=markers[cache_mode], linewidth=3, markersize=10, \n",
    "            label=cache_mode.upper(), color=colors_dict[cache_mode], alpha=0.8)\n",
    "\n",
    "ax1.set_title('‚è±Ô∏è Execution Time vs Data Size', fontweight='bold', pad=15)\n",
    "ax1.set_xlabel('Data Size (records)', fontweight='bold')\n",
    "ax1.set_ylabel('Execution Time (seconds)', fontweight='bold')\n",
    "ax1.legend(framealpha=0.9, fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_facecolor('#FAFAFA')\n",
    "\n",
    "# 2. Memory Usage vs Data Size\n",
    "ax2 = axes[1]\n",
    "for cache_mode in df['cache_mode'].unique():\n",
    "    cache_data = df[df['cache_mode'] == cache_mode].sort_values('data_size')\n",
    "    ax2.plot(cache_data['data_size'], cache_data['max_memory'], \n",
    "            marker=markers[cache_mode], linewidth=3, markersize=10, \n",
    "            label=cache_mode.upper(), color=colors_dict[cache_mode], alpha=0.8)\n",
    "\n",
    "ax2.set_title('üíæ Memory Usage vs Data Size', fontweight='bold', pad=15)\n",
    "ax2.set_xlabel('Data Size (records)', fontweight='bold')\n",
    "ax2.set_ylabel('Max Memory Usage (MB)', fontweight='bold')\n",
    "ax2.legend(framealpha=0.9, fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_facecolor('#FAFAFA')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scalability_analysis.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Scalability analysis created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9476dae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ PERFORMANCE IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä EXECUTION TIME COMPARISON:\n",
      "----------------------------------------\n",
      "üî¥ Baseline (No Caching): 3.778s\n",
      "üî¥ FIFO Caching: 4.009s (-6.1%)\n",
      "üü¢ LRU Caching: 3.433s (+9.1%)\n",
      "\n",
      "üèÜ LRU vs FIFO Improvement: +14.4%\n",
      "\n",
      "üíæ MEMORY USAGE ANALYSIS:\n",
      "----------------------------------------\n",
      "üü° FIFO        : 0.00 MB average increase\n",
      "üü¢ LRU         : 0.21 MB average increase\n",
      "üî¥ NONE        : 1.90 MB average increase\n",
      "\n",
      "üéØ CACHE HIT RATES:\n",
      "----------------------------------------\n",
      "üü¢ FIFO        : 90.9%\n",
      "üü¢ LRU         : 90.9%\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Performance Improvement Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ PERFORMANCE IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get average performance by cache mode\n",
    "perf_by_mode = df.groupby('cache_mode')['avg_execution_time'].mean()\n",
    "memory_by_mode = df.groupby('cache_mode')['memory_increase'].mean()\n",
    "cache_efficiency = df[df['cache_mode'] != 'none'].groupby('cache_mode')['cache_hit_rate'].mean()\n",
    "\n",
    "print(f\"\\nüìä EXECUTION TIME COMPARISON:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'none' in perf_by_mode.index:\n",
    "    baseline = perf_by_mode['none']\n",
    "    print(f\"üî¥ Baseline (No Caching): {baseline:.3f}s\")\n",
    "    \n",
    "    if 'fifo' in perf_by_mode.index:\n",
    "        fifo_improvement = ((baseline - perf_by_mode['fifo']) / baseline) * 100\n",
    "        icon = \"üü¢\" if fifo_improvement > 0 else \"üî¥\"\n",
    "        print(f\"{icon} FIFO Caching: {perf_by_mode['fifo']:.3f}s ({fifo_improvement:+.1f}%)\")\n",
    "    \n",
    "    if 'lru' in perf_by_mode.index:\n",
    "        lru_improvement = ((baseline - perf_by_mode['lru']) / baseline) * 100\n",
    "        icon = \"üü¢\" if lru_improvement > 0 else \"üî¥\"\n",
    "        print(f\"{icon} LRU Caching: {perf_by_mode['lru']:.3f}s ({lru_improvement:+.1f}%)\")\n",
    "        \n",
    "    # Compare LRU vs FIFO\n",
    "    if 'fifo' in perf_by_mode.index and 'lru' in perf_by_mode.index:\n",
    "        lru_vs_fifo = ((perf_by_mode['fifo'] - perf_by_mode['lru']) / perf_by_mode['fifo']) * 100\n",
    "        icon = \"üèÜ\" if lru_vs_fifo > 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"\\n{icon} LRU vs FIFO Improvement: {lru_vs_fifo:+.1f}%\")\n",
    "\n",
    "print(f\"\\nüíæ MEMORY USAGE ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "for mode, memory in memory_by_mode.items():\n",
    "    emoji = \"üî¥\" if mode == 'none' else \"üü°\" if mode == 'fifo' else \"üü¢\"\n",
    "    print(f\"{emoji} {mode.upper():<12}: {memory:.2f} MB average increase\")\n",
    "\n",
    "if len(cache_efficiency) > 0:\n",
    "    print(f\"\\nüéØ CACHE HIT RATES:\")\n",
    "    print(\"-\" * 40)\n",
    "    for mode, hit_rate in cache_efficiency.items():\n",
    "        emoji = \"üü¢\" if hit_rate > 85 else \"üü°\" if hit_rate > 70 else \"üî¥\"\n",
    "        print(f\"{emoji} {mode.upper():<12}: {hit_rate:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2e0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Performance summary table created and saved to performance_summary.csv\n",
      "\n",
      "üìä Performance Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cache Mode</th>\n",
       "      <th>Avg Execution Time (s)</th>\n",
       "      <th>Min Execution Time (s)</th>\n",
       "      <th>Max Execution Time (s)</th>\n",
       "      <th>Std Deviation (s)</th>\n",
       "      <th>Avg Memory Increase (MB)</th>\n",
       "      <th>Cache Hit Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONE</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.416</td>\n",
       "      <td>6.806</td>\n",
       "      <td>2.756</td>\n",
       "      <td>1.90</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIFO</td>\n",
       "      <td>4.009</td>\n",
       "      <td>1.468</td>\n",
       "      <td>7.540</td>\n",
       "      <td>3.154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LRU</td>\n",
       "      <td>3.433</td>\n",
       "      <td>1.444</td>\n",
       "      <td>5.649</td>\n",
       "      <td>2.112</td>\n",
       "      <td>0.21</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cache Mode Avg Execution Time (s) Min Execution Time (s)  \\\n",
       "0       NONE                  3.778                  1.416   \n",
       "1       FIFO                  4.009                  1.468   \n",
       "2        LRU                  3.433                  1.444   \n",
       "\n",
       "  Max Execution Time (s) Std Deviation (s) Avg Memory Increase (MB)  \\\n",
       "0                  6.806             2.756                     1.90   \n",
       "1                  7.540             3.154                     0.00   \n",
       "2                  5.649             2.112                     0.21   \n",
       "\n",
       "  Cache Hit Rate (%)  \n",
       "0                N/A  \n",
       "1               90.9  \n",
       "2               90.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance Summary Table\n",
    "summary_stats = []\n",
    "\n",
    "for cache_mode in df['cache_mode'].unique():\n",
    "    cache_data = df[df['cache_mode'] == cache_mode]\n",
    "    \n",
    "    stats = {\n",
    "        'Cache Mode': cache_mode.upper(),\n",
    "        'Avg Execution Time (s)': f\"{cache_data['avg_execution_time'].mean():.3f}\",\n",
    "        'Min Execution Time (s)': f\"{cache_data['avg_execution_time'].min():.3f}\",\n",
    "        'Max Execution Time (s)': f\"{cache_data['avg_execution_time'].max():.3f}\",\n",
    "        'Std Deviation (s)': f\"{cache_data['avg_execution_time'].std():.3f}\",\n",
    "        'Avg Memory Increase (MB)': f\"{cache_data['memory_increase'].mean():.2f}\",\n",
    "        'Cache Hit Rate (%)': f\"{cache_data['cache_hit_rate'].mean():.1f}\" if cache_mode != 'none' else 'N/A'\n",
    "    }\n",
    "    summary_stats.append(stats)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Create styled table visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns,\n",
    "                cellLoc='center', loc='center', bbox=[0, 0, 1, 1])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 2.5)\n",
    "\n",
    "# Style the table with professional colors\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0:  # Header row\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "        cell.set_facecolor('#2C3E50')\n",
    "    else:\n",
    "        if i == 1:  # NONE row\n",
    "            cell.set_facecolor('#FFE5E5')\n",
    "        elif i == 2:  # FIFO row\n",
    "            cell.set_facecolor('#E5F7F5')\n",
    "        else:  # LRU row\n",
    "            cell.set_facecolor('#E5F3FF')\n",
    "        \n",
    "        if j == 0:  # First column (Cache Mode)\n",
    "            cell.set_text_props(weight='bold')\n",
    "\n",
    "plt.title('üìã Comprehensive Performance Summary Table', \n",
    "          fontsize=16, fontweight='bold', pad=30)\n",
    "plt.savefig('performance_summary_table.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_df.to_csv('performance_summary.csv', index=False)\n",
    "print(\"‚úÖ Performance summary table created and saved to performance_summary.csv\")\n",
    "\n",
    "# Display the dataframe\n",
    "print(\"\\nüìä Performance Summary:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a983ac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ ANALYSIS COMPLETE üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   ‚úÖ performance_comparison_dashboard.png - Main performance overview\n",
      "   ‚úÖ performance_heatmap.png - Detailed scenario comparison\n",
      "   ‚úÖ scalability_analysis.png - Data size impact analysis\n",
      "   ‚úÖ performance_summary_table.png - Comprehensive metrics table\n",
      "   ‚úÖ performance_summary.csv - Exportable summary data\n",
      "\n",
      "üîç Key Findings:\n",
      "   üöÄ LRU caching provides 9.1% performance improvement over no caching\n",
      "   üèÜ LRU outperforms FIFO by 14.4%\n",
      "   üéØ Average cache hit rate: 90.9%\n",
      "\n",
      "üí° Recommendations:\n",
      "   1. Deploy LRU caching for optimal performance\n",
      "   2. Monitor cache hit rates in production\n",
      "   3. Consider cache size tuning for memory efficiency\n",
      "   4. Implement gradual rollout with performance monitoring\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Results Summary\n",
    "print(\"\\n\" + \"üéâ\" * 20 + \" ANALYSIS COMPLETE \" + \"üéâ\" * 20)\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"   ‚úÖ performance_comparison_dashboard.png - Main performance overview\")\n",
    "print(\"   ‚úÖ performance_heatmap.png - Detailed scenario comparison\") \n",
    "print(\"   ‚úÖ scalability_analysis.png - Data size impact analysis\")\n",
    "print(\"   ‚úÖ performance_summary_table.png - Comprehensive metrics table\")\n",
    "print(\"   ‚úÖ performance_summary.csv - Exportable summary data\")\n",
    "\n",
    "print(\"\\nüîç Key Findings:\")\n",
    "if 'none' in perf_by_mode.index and 'lru' in perf_by_mode.index:\n",
    "    lru_improvement = ((perf_by_mode['none'] - perf_by_mode['lru']) / perf_by_mode['none']) * 100\n",
    "    print(f\"   üöÄ LRU caching provides {lru_improvement:.1f}% performance improvement over no caching\")\n",
    "\n",
    "if 'fifo' in perf_by_mode.index and 'lru' in perf_by_mode.index:\n",
    "    lru_vs_fifo = ((perf_by_mode['fifo'] - perf_by_mode['lru']) / perf_by_mode['fifo']) * 100\n",
    "    print(f\"   üèÜ LRU outperforms FIFO by {lru_vs_fifo:.1f}%\")\n",
    "\n",
    "avg_hit_rate = cache_efficiency.mean() if len(cache_efficiency) > 0 else 0\n",
    "print(f\"   üéØ Average cache hit rate: {avg_hit_rate:.1f}%\")\n",
    "\n",
    "print(\"\\nüí° Recommendations:\")\n",
    "print(\"   1. Deploy LRU caching for optimal performance\")\n",
    "print(\"   2. Monitor cache hit rates in production\")\n",
    "print(\"   3. Consider cache size tuning for memory efficiency\")\n",
    "print(\"   4. Implement gradual rollout with performance monitoring\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
