{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT id, name FROM employees MATCH_RECOGNIZE ( PARTITION BY department, region ORDER BY hire_date MEASURES salary AS avg_salary PATTERN (A) DEFINE A AS salary > 1000 );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=id, metadata={}), SelectItem(expression=name, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='employees')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['department', 'region'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='hire_date', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='salary', alias='avg_salary', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='A', metadata={'variables': ['A'], 'base_variables': ['A']})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition='salary>1000')])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'salary': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from define condition 'salary>1000': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Pattern variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Referenced variables: set()\n",
      "DEBUG:src.parser.match_recognize_extractor:Required variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Defined variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Subset variables: {}\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: salary\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Recognize Output:\n",
      "   id   name department region   hire_date  salary  avg_salary  MATCH_NUMBER\n",
      "0   6  Frank  Marketing   West  2021-01-01    1150        1150             1\n",
      "1   5    Eve      Sales   East  2021-01-01    1250        1250             1\n",
      "2   1  Alice      Sales   West  2021-01-01    1200        1200             1\n",
      "3   2    Bob      Sales   West  2021-01-02    1300        1300             2\n",
      "4   4  Diana      Sales   West  2021-01-04    1100        1100             3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "# Example with your original query\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\", \"region\": \"West\", \n",
    "     \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"department\": \"Sales\", \"region\": \"West\", \n",
    "     \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \n",
    "     \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\", \"department\": \"Sales\", \"region\": \"West\", \n",
    "     \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "    # Add more departments/regions\n",
    "    {\"id\": 5, \"name\": \"Eve\", \"department\": \"Sales\", \"region\": \"East\", \n",
    "     \"hire_date\": \"2021-01-01\", \"salary\": 1250},\n",
    "    {\"id\": 6, \"name\": \"Frank\", \"department\": \"Marketing\", \"region\": \"West\", \n",
    "     \"hire_date\": \"2021-01-01\", \"salary\": 1150},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT id, name \n",
    "FROM employees \n",
    "MATCH_RECOGNIZE (\n",
    "    PARTITION BY department, region\n",
    "    ORDER BY hire_date\n",
    "    MEASURES salary AS avg_salary\n",
    "    PATTERN (A)\n",
    "    DEFINE A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "result = match_recognize(query, df)\n",
    "print(\"Match Recognize Output:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7949/3405666025.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT * FROM orders MATCH_RECOGNIZE ( PARTITION BY customer_name ORDER BY order_date MEASURES FIRST(order_date) AS start_date, LAST(order_date) AS end_date, SUM(order_amount) AS total_amount, COUNT(*) AS order_count PATTERN (A+) DEFINE A AS order_amount > 0 );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=*, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='orders')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['customer_name'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='order_date', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='FIRST(order_date)', alias='start_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='LAST(order_date)', alias='end_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='SUM(order_amount)', alias='total_amount', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='COUNT(*)', alias='order_count', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='A+', metadata={'variables': ['A+'], 'base_variables': ['A']})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition='order_amount>0')])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'FIRST(order_date)': ['order_date']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'LAST(order_date)': ['order_date']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'SUM(order_amount)': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'COUNT(*)': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from define condition 'order_amount>0': []\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Referenced variable(s) {'order_date'} not found in the PATTERN clause or SUBSET definitions. (Line: 2, Column: 7)\nSnippet: ordersMATCH_RECOGNIZE(PARTITIONBYcustomer_nameORDERBYorder_dateMEASURESFIRST(order_date)ASstart_date,LAST(order_date)ASend_date,SUM(order_amount)AStotal_amount,COUNT(*)ASorder_countPATTERN(A+)DEFINEAASorder_amount>0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     14\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mFROM   orders\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m);\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m match_recognize(query, df)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatch Recognize Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/executor/match_recognize.py:36\u001b[0m, in \u001b[0;36mmatch_recognize\u001b[0;34m(query, df)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mExecute a MATCH_RECOGNIZE query against a Pandas DataFrame.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mEnhanced with support for all MATCH_RECOGNIZE features.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Parse the query and build the AST\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m ast \u001b[38;5;241m=\u001b[39m parse_full_query(query)\n\u001b[1;32m     37\u001b[0m mr_clause \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mmatch_recognize\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mr_clause:\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/parser/match_recognize_extractor.py:646\u001b[0m, in \u001b[0;36mparse_full_query\u001b[0;34m(query, dialect)\u001b[0m\n\u001b[1;32m    644\u001b[0m tree \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse()\n\u001b[1;32m    645\u001b[0m extractor \u001b[38;5;241m=\u001b[39m FullQueryExtractor(query)\n\u001b[0;32m--> 646\u001b[0m extractor\u001b[38;5;241m.\u001b[39mvisit(tree)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FullQueryAST(extractor\u001b[38;5;241m.\u001b[39mselect_clause, extractor\u001b[38;5;241m.\u001b[39mfrom_clause, extractor\u001b[38;5;241m.\u001b[39mmatch_recognize)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/antlr4/tree/Tree.py:34\u001b[0m, in \u001b[0;36mParseTreeVisitor.visit\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit\u001b[39m(\u001b[38;5;28mself\u001b[39m, tree):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39maccept(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/grammar/TrinoParser.py:2122\u001b[0m, in \u001b[0;36mTrinoParser.ParseContext.accept\u001b[0;34m(self, visitor)\u001b[0m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor:ParseTreeVisitor):\n\u001b[1;32m   2121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m( visitor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitParse\u001b[39m\u001b[38;5;124m\"\u001b[39m ):\n\u001b[0;32m-> 2122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitParse(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitChildren(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/parser/match_recognize_extractor.py:581\u001b[0m, in \u001b[0;36mFullQueryExtractor.visitParse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisitParse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx: TrinoParser\u001b[38;5;241m.\u001b[39mParseContext):\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitChildren(ctx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/antlr4/tree/Tree.py:44\u001b[0m, in \u001b[0;36mParseTreeVisitor.visitChildren\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     43\u001b[0m     c \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mgetChild(i)\n\u001b[0;32m---> 44\u001b[0m     childResult \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39maccept(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     45\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregateResult(result, childResult)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/grammar/TrinoParser.py:2204\u001b[0m, in \u001b[0;36mTrinoParser.StatementsContext.accept\u001b[0;34m(self, visitor)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor:ParseTreeVisitor):\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m( visitor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitStatements\u001b[39m\u001b[38;5;124m\"\u001b[39m ):\n\u001b[0;32m-> 2204\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitStatements(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitChildren(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/grammar/TrinoParserVisitor.py:19\u001b[0m, in \u001b[0;36mTrinoParserVisitor.visitStatements\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisitStatements\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx:TrinoParser\u001b[38;5;241m.\u001b[39mStatementsContext):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitChildren(ctx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/antlr4/tree/Tree.py:44\u001b[0m, in \u001b[0;36mParseTreeVisitor.visitChildren\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     43\u001b[0m     c \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mgetChild(i)\n\u001b[0;32m---> 44\u001b[0m     childResult \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39maccept(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     45\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregateResult(result, childResult)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/grammar/TrinoParser.py:2301\u001b[0m, in \u001b[0;36mTrinoParser.SingleStatementContext.accept\u001b[0;34m(self, visitor)\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor:ParseTreeVisitor):\n\u001b[1;32m   2300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m( visitor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitSingleStatement\u001b[39m\u001b[38;5;124m\"\u001b[39m ):\n\u001b[0;32m-> 2301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitSingleStatement(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitChildren(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/parser/match_recognize_extractor.py:601\u001b[0m, in \u001b[0;36mFullQueryExtractor.visitSingleStatement\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_recognize:\n\u001b[1;32m    600\u001b[0m     extractor \u001b[38;5;241m=\u001b[39m MatchRecognizeExtractor()\n\u001b[0;32m--> 601\u001b[0m     extractor\u001b[38;5;241m.\u001b[39mvisit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_recognize)\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_recognize \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mast\n\u001b[1;32m    603\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted MATCH_RECOGNIZE clause via recursive search.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/antlr4/tree/Tree.py:34\u001b[0m, in \u001b[0;36mParseTreeVisitor.visit\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit\u001b[39m(\u001b[38;5;28mself\u001b[39m, tree):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39maccept(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/grammar/TrinoParser.py:11855\u001b[0m, in \u001b[0;36mTrinoParser.PatternRecognitionContext.accept\u001b[0;34m(self, visitor)\u001b[0m\n\u001b[1;32m  11853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor:ParseTreeVisitor):\n\u001b[1;32m  11854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m( visitor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitPatternRecognition\u001b[39m\u001b[38;5;124m\"\u001b[39m ):\n\u001b[0;32m> 11855\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitPatternRecognition(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m  11856\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  11857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m visitor\u001b[38;5;241m.\u001b[39mvisitChildren(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/parser/match_recognize_extractor.py:150\u001b[0m, in \u001b[0;36mMatchRecognizeExtractor.visitPatternRecognition\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_clauses(ctx)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_identifiers(ctx)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_pattern_variables_defined(ctx)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_function_usage(ctx)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/parser/match_recognize_extractor.py:556\u001b[0m, in \u001b[0;36mMatchRecognizeExtractor.validate_pattern_variables_defined\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains undefined pattern variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_elements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    553\u001b[0m                         line\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mline, column\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mcolumn, snippet\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mgetText())\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReferenced variable(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the PATTERN clause or SUBSET definitions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    557\u001b[0m                     line\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mline, column\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mcolumn, snippet\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mgetText())\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefined variable(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the PATTERN clause.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    561\u001b[0m                     line\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mline, column\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mcolumn, snippet\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mgetText())\n",
      "\u001b[0;31mParserError\u001b[0m: Referenced variable(s) {'order_date'} not found in the PATTERN clause or SUBSET definitions. (Line: 2, Column: 7)\nSnippet: ordersMATCH_RECOGNIZE(PARTITIONBYcustomer_nameORDERBYorder_dateMEASURESFIRST(order_date)ASstart_date,LAST(order_date)ASend_date,SUM(order_amount)AStotal_amount,COUNT(*)ASorder_countPATTERN(A+)DEFINEAASorder_amount>0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5, 6],\n",
    "    'customer_name': ['John', 'John', 'Mary', 'John', 'Mary', 'Mary'],\n",
    "    'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
    "                                   '03-JAN-2023', '04-JAN-2023', '05-JAN-2023']),\n",
    "    'order_amount': [100, 200, 150, 120, 180, 80]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM   orders\n",
    "MATCH_RECOGNIZE (\n",
    "  PARTITION BY customer_name\n",
    "  ORDER BY order_date\n",
    "  MEASURES\n",
    "    FIRST(order_date) AS start_date,\n",
    "    LAST(order_date) AS end_date,\n",
    "    SUM(order_amount) AS total_amount,\n",
    "    COUNT(*) AS order_count\n",
    "  PATTERN (A+)\n",
    "  DEFINE A AS order_amount > 0\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "result = match_recognize(query, df)\n",
    "print(\"Match Recognize Output:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104695/4122375284.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT * FROM orders MATCH_RECOGNIZE ( PARTITION BY customer ORDER BY order_date MEASURES FIRST(A.order_date) AS start_date, LAST(A.order_date) AS end_date, SUM(A.amount) AS total_amount, COUNT(*) AS order_count PATTERN (A+) DEFINE A AS amount > 0 );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=*, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='orders')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['customer'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='order_date', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='FIRST(A.order_date)', alias='start_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='LAST(A.order_date)', alias='end_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='SUM(A.amount)', alias='total_amount', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='COUNT(*)', alias='order_count', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='A+', metadata={'variables': ['A+'], 'base_variables': ['A']})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition='amount>0')])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'FIRST(A.order_date)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'LAST(A.order_date)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'SUM(A.amount)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'COUNT(*)': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from define condition 'amount>0': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Pattern variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Referenced variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Required variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Defined variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Subset variables: {}\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: FIRST(A.order_date)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: LAST(A.order_date)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: SUM(A.amount)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: COUNT(*)\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Recognize Output:\n",
      "   order_id customer order_date  amount start_date end_date  total_amount  \\\n",
      "0         1     John 2023-01-01     100       None     None           100   \n",
      "1         2     John 2023-01-02     200       None     None           200   \n",
      "2         4     John 2023-01-03     120       None     None           120   \n",
      "3         3     Mary 2023-01-02     150       None     None           150   \n",
      "4         5     Mary 2023-01-04     180       None     None           180   \n",
      "5         6     Mary 2023-01-05      80       None     None            80   \n",
      "\n",
      "   order_count  MATCH_NUMBER  \n",
      "0            1             1  \n",
      "1            1             2  \n",
      "2            1             3  \n",
      "3            1             1  \n",
      "4            1             2  \n",
      "5            1             3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5, 6],\n",
    "    'customer': ['John', 'John', 'Mary', 'John', 'Mary', 'Mary'],\n",
    "    'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
    "                                   '03-JAN-2023', '04-JAN-2023', '05-JAN-2023']),\n",
    "    'amount': [100, 200, 150, 120, 180, 80]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Corrected query with proper column names and pattern variable prefixes\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM   orders\n",
    "MATCH_RECOGNIZE (\n",
    "  PARTITION BY customer\n",
    "  ORDER BY order_date\n",
    "  MEASURES\n",
    "    FIRST(A.order_date) AS start_date,\n",
    "    LAST(A.order_date) AS end_date,\n",
    "    SUM(A.amount) AS total_amount,\n",
    "    COUNT(*) AS order_count\n",
    "  PATTERN (A+)\n",
    "  DEFINE A AS amount > 0\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "result = match_recognize(query, df)\n",
    "print(\"Match Recognize Output:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       price  volume    return stock\n",
      "0  2023-01-01  100.000000    1459  0.000000  AAPL\n",
      "1  2023-01-02  100.496714    4385  0.004967  AAPL\n",
      "2  2023-01-03  100.357763    1021 -0.001383  AAPL\n",
      "3  2023-01-04  101.007769    3300  0.006477  AAPL\n",
      "4  2023-01-05  102.546147    1747  0.015230  AAPL\n",
      "5  2023-01-06   92.291533    3904 -0.100000  AAPL\n",
      "6  2023-01-07   95.060279    4632  0.030000  AAPL\n",
      "7  2023-01-08   94.837692    1474 -0.002342  AAPL\n",
      "8  2023-01-09   94.615642    2082 -0.002341  AAPL\n",
      "9  2023-01-10   96.109824    3558  0.015792  AAPL\n",
      "10 2023-01-11  100.915315    4753  0.050000  GOOG\n",
      "11 2023-01-12   97.887856    3047 -0.030000  GOOG\n",
      "12 2023-01-13   94.951220    4547 -0.030000  GOOG\n",
      "13 2023-01-14   98.749269    3747  0.040000  GOOG\n",
      "14 2023-01-15  102.699240    1975  0.040000  GOOG\n",
      "15 2023-01-16  103.487389    2806  0.007674  GOOG\n",
      "16 2023-01-17  103.001542    1189 -0.004695  GOOG\n",
      "17 2023-01-18  103.560388    4005  0.005426  GOOG\n",
      "18 2023-01-19  103.080470    3734 -0.004634  GOOG\n",
      "19 2023-01-20  102.600394    4005 -0.004657  GOOG\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create stock price data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2023-01-01', periods=20, freq='D')\n",
    "prices = [100]\n",
    "\n",
    "# Generate a realistic price series with some patterns\n",
    "for i in range(1, 20):\n",
    "    if i == 5:  # Sharp drop\n",
    "        prices.append(prices[-1] * 0.9)  # 10% drop\n",
    "    elif i == 6:  # Slight recovery\n",
    "        prices.append(prices[-1] * 1.03)  # 3% up\n",
    "    elif i == 10:  # Peak\n",
    "        prices.append(prices[-1] * 1.05)  # 5% up\n",
    "    elif i == 11 or i == 12:  # Double down\n",
    "        prices.append(prices[-1] * 0.97)  # 3% down\n",
    "    elif i == 13 or i == 14:  # Double up\n",
    "        prices.append(prices[-1] * 1.04)  # 4% up\n",
    "    else:\n",
    "        # Random movement\n",
    "        prices.append(prices[-1] * (1 + np.random.normal(0, 0.01)))  # 1% volatility\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = [0] + [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]\n",
    "\n",
    "# Create the dataframe\n",
    "stock_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'price': prices,\n",
    "    'volume': np.random.randint(1000, 5000, size=len(prices)),\n",
    "    'return': returns,\n",
    "    'stock': ['AAPL'] * 10 + ['GOOG'] * 10  # Two different stocks\n",
    "})\n",
    "\n",
    "# Show the dataframe\n",
    "print(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112179/4131321436.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT * FROM orders MATCH_RECOGNIZE ( PARTITION BY customer ORDER BY order_date MEASURES FIRST(A.order_date) AS start_date, LAST(A.order_date) AS end_date, SUM(A.amount) AS total_amount, COUNT(*) AS order_count ONE ROW PER MATCH PATTERN (A+) DEFINE A AS amount > 0 );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=*, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='orders')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['customer'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='order_date', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='FIRST(A.order_date)', alias='start_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='LAST(A.order_date)', alias='end_date', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='SUM(A.amount)', alias='total_amount', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False), Measure(expression='COUNT(*)', alias='order_count', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONEROWPERMATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONE ROW PER MATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='A+', metadata={'variables': ['A+'], 'base_variables': ['A']})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition='amount>0')])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A+'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A+\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'FIRST(A.order_date)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'LAST(A.order_date)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'SUM(A.amount)': ['A']\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'COUNT(*)': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from define condition 'amount>0': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Pattern variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Referenced variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Required variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Defined variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Subset variables: {}\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: FIRST(A.order_date)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: LAST(A.order_date)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: SUM(A.amount)\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: COUNT(*)\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating expression: FIRST(A.order_date)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating navigation function: FIRST(A.order_date)\n",
      "Function: FIRST, Args: ['A.order_date']\n",
      "Evaluating expression: LAST(A.order_date)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating navigation function: LAST(A.order_date)\n",
      "Function: LAST, Args: ['A.order_date']\n",
      "Evaluating expression: SUM(A.amount)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating aggregate function: sum(A.amount)\n",
      "Evaluating expression: COUNT(*)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating aggregate function: count(*)\n",
      "Evaluating expression: FIRST(A.order_date)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating navigation function: FIRST(A.order_date)\n",
      "Function: FIRST, Args: ['A.order_date']\n",
      "Evaluating expression: LAST(A.order_date)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating navigation function: LAST(A.order_date)\n",
      "Function: LAST, Args: ['A.order_date']\n",
      "Evaluating expression: SUM(A.amount)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating aggregate function: sum(A.amount)\n",
      "Evaluating expression: COUNT(*)\n",
      "Context variables: {'A': [0, 1, 2]}\n",
      "Number of rows: 3\n",
      "Evaluating aggregate function: count(*)\n",
      "Match Recognize Output:\n",
      "   order_id customer order_date  amount start_date   end_date  total_amount  \\\n",
      "0         1     John 2023-01-01     100 2023-01-01 2023-01-03           420   \n",
      "1         3     Mary 2023-01-02     150 2023-01-02 2023-01-05           410   \n",
      "\n",
      "   order_count  MATCH_NUMBER  \n",
      "0            3             1  \n",
      "1            3             1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5, 6],\n",
    "    'customer': ['John', 'John', 'Mary', 'John', 'Mary', 'Mary'],\n",
    "    'order_date': pd.to_datetime(['01-JAN-2023', '02-JAN-2023', '02-JAN-2023',\n",
    "                                   '03-JAN-2023', '04-JAN-2023', '05-JAN-2023']),\n",
    "    'amount': [100, 200, 150, 120, 180, 80]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Modified query to test multi-row pattern matching\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM   orders\n",
    "MATCH_RECOGNIZE (\n",
    "  PARTITION BY customer\n",
    "  ORDER BY order_date\n",
    "  MEASURES\n",
    "    FIRST(A.order_date) AS start_date,\n",
    "    LAST(A.order_date) AS end_date,\n",
    "    SUM(A.amount) AS total_amount,\n",
    "    COUNT(*) AS order_count\n",
    "  ONE ROW PER MATCH\n",
    "  PATTERN (A+)\n",
    "  DEFINE A AS amount > 0\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "result = match_recognize(query, df)\n",
    "print(\"Match Recognize Output:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT id, name FROM employees MATCH_RECOGNIZE ( PARTITION BY department, region ORDER BY hire_date MEASURES salary AS avg_salary PATTERN (A) DEFINE A AS salary > 1000 );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=id, metadata={}), SelectItem(expression=name, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='employees')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['department', 'region'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='hire_date', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='salary', alias='avg_salary', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=False)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='A', metadata={'variables': ['A'], 'base_variables': ['A']})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition='salary>1000')])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': ['A'], 'base_variables': ['A']}\n",
      "DEBUG:src.parser.match_recognize_extractor:PATTERN clause validated successfully: A\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from measure 'salary': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted variables from define condition 'salary>1000': []\n",
      "DEBUG:src.parser.match_recognize_extractor:Pattern variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Referenced variables: set()\n",
      "DEBUG:src.parser.match_recognize_extractor:Required variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Defined variables: {'A'}\n",
      "DEBUG:src.parser.match_recognize_extractor:Subset variables: {}\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: salary\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 167\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# Run all tests\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     test_basic_pattern()\n\u001b[1;32m    168\u001b[0m     test_price_trend()\n\u001b[1;32m    169\u001b[0m     test_complex_pattern()\n",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m, in \u001b[0;36mtest_basic_pattern\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     16\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mSELECT id, name \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mFROM employees \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m);\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m result \u001b[38;5;241m=\u001b[39m match_recognize(query, df)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasic Pattern Test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/executor/match_recognize.py:119\u001b[0m, in \u001b[0;36mmatch_recognize\u001b[0;34m(query, df)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Create matcher and find matches\u001b[39;00m\n\u001b[1;32m    118\u001b[0m matcher \u001b[38;5;241m=\u001b[39m EnhancedMatcher(dfa)\n\u001b[0;32m--> 119\u001b[0m partition_results \u001b[38;5;241m=\u001b[39m matcher\u001b[38;5;241m.\u001b[39mfind_matches(rows, config, measures)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Add partition columns if needed\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partition_by:\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/matcher/matcher.py:48\u001b[0m, in \u001b[0;36mEnhancedMatcher.find_matches\u001b[0;34m(self, rows, config, measures)\u001b[0m\n\u001b[1;32m     45\u001b[0m context \u001b[38;5;241m=\u001b[39m RowContext()\n\u001b[1;32m     46\u001b[0m context\u001b[38;5;241m.\u001b[39mmatch_number \u001b[38;5;241m=\u001b[39m match_number\n\u001b[0;32m---> 48\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_single_match(rows, i, context)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[1;32m     51\u001b[0m     start_idx, end_idx \u001b[38;5;241m=\u001b[39m match[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m], match[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/matcher/matcher.py:113\u001b[0m, in \u001b[0;36mEnhancedMatcher._find_single_match\u001b[0;34m(self, rows, start_idx, context)\u001b[0m\n\u001b[1;32m    110\u001b[0m matched_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfa\u001b[38;5;241m.\u001b[39mstates[state]\u001b[38;5;241m.\u001b[39mtransitions:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transition\u001b[38;5;241m.\u001b[39mcondition(row, context):\n\u001b[1;32m    114\u001b[0m         next_state \u001b[38;5;241m=\u001b[39m transition\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m    115\u001b[0m         matched_var \u001b[38;5;241m=\u001b[39m transition\u001b[38;5;241m.\u001b[39mvariable\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'condition'"
     ]
    }
   ],
   "source": [
    "# test_match_recognize.py\n",
    "\n",
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "def test_basic_pattern():\n",
    "    \"\"\"Test basic pattern matching with A+ pattern.\"\"\"\n",
    "    data = [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "        {\"id\": 4, \"name\": \"Diana\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT id, name \n",
    "    FROM employees \n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY department, region\n",
    "        ORDER BY hire_date\n",
    "        MEASURES salary AS avg_salary\n",
    "        PATTERN (A)\n",
    "        DEFINE A AS salary > 1000\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    result = match_recognize(query, df)\n",
    "    print(\"Basic Pattern Test:\")\n",
    "    print(result)\n",
    "\n",
    "def test_price_trend():\n",
    "    \"\"\"Test price trend pattern (increasing then decreasing).\"\"\"\n",
    "    data = [\n",
    "        {\"order_id\": 1, \"customer_id\": \"C1\", \"price\": 100, \"order_date\": \"2023-01-01\"},\n",
    "        {\"order_id\": 2, \"customer_id\": \"C1\", \"price\": 150, \"order_date\": \"2023-01-02\"},\n",
    "        {\"order_id\": 3, \"customer_id\": \"C1\", \"price\": 200, \"order_date\": \"2023-01-03\"},\n",
    "        {\"order_id\": 4, \"customer_id\": \"C1\", \"price\": 180, \"order_date\": \"2023-01-04\"},\n",
    "        {\"order_id\": 5, \"customer_id\": \"C1\", \"price\": 160, \"order_date\": \"2023-01-05\"},\n",
    "        {\"order_id\": 6, \"customer_id\": \"C2\", \"price\": 120, \"order_date\": \"2023-01-01\"},\n",
    "        {\"order_id\": 7, \"customer_id\": \"C2\", \"price\": 140, \"order_date\": \"2023-01-02\"},\n",
    "        {\"order_id\": 8, \"customer_id\": \"C2\", \"price\": 130, \"order_date\": \"2023-01-03\"},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM orders\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY customer_id\n",
    "        ORDER BY order_date\n",
    "        MEASURES \n",
    "            FIRST(A.price) AS start_price,\n",
    "            LAST(A.price) AS peak_price,\n",
    "            LAST(B.price) AS end_price\n",
    "        ONE ROW PER MATCH\n",
    "        AFTER MATCH SKIP TO NEXT ROW\n",
    "        PATTERN (A+ B+)\n",
    "        DEFINE\n",
    "            A AS PREV(price) IS NULL OR price > PREV(price),\n",
    "            B AS price < PREV(price)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    result = match_recognize(query, df)\n",
    "    print(\"\\nPrice Trend Test:\")\n",
    "    print(result)\n",
    "\n",
    "def test_complex_pattern():\n",
    "    \"\"\"Test complex pattern with alternation and quantifiers.\"\"\"\n",
    "    data = [\n",
    "        {\"event_id\": 1, \"sequence\": \"A\", \"value\": 10, \"timestamp\": \"2023-01-01 10:00:00\"},\n",
    "        {\"event_id\": 2, \"sequence\": \"B\", \"value\": 20, \"timestamp\": \"2023-01-01 10:01:00\"},\n",
    "        {\"event_id\": 3, \"sequence\": \"A\", \"value\": 30, \"timestamp\": \"2023-01-01 10:02:00\"},\n",
    "        {\"event_id\": 4, \"sequence\": \"C\", \"value\": 40, \"timestamp\": \"2023-01-01 10:03:00\"},\n",
    "        {\"event_id\": 5, \"sequence\": \"B\", \"value\": 50, \"timestamp\": \"2023-01-01 10:04:00\"},\n",
    "        {\"event_id\": 6, \"sequence\": \"A\", \"value\": 60, \"timestamp\": \"2023-01-01 10:05:00\"},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM events\n",
    "    MATCH_RECOGNIZE (\n",
    "        ORDER BY timestamp\n",
    "        MEASURES \n",
    "            FIRST(A.value) AS first_value,\n",
    "            LAST(B.value) AS last_value,\n",
    "            COUNT(*) AS pattern_length\n",
    "        ALL ROWS PER MATCH\n",
    "        PATTERN ((A B+) | (B A+))\n",
    "        SUBSET U = (A, B)\n",
    "        DEFINE\n",
    "            A AS sequence = 'A',\n",
    "            B AS sequence = 'B'\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    result = match_recognize(query, df)\n",
    "    print(\"\\nComplex Pattern Test:\")\n",
    "    print(result)\n",
    "\n",
    "def test_running_measures():\n",
    "    \"\"\"Test running measures and aggregations.\"\"\"\n",
    "    data = [\n",
    "        {\"id\": 1, \"metric\": 100, \"timestamp\": \"2023-01-01\"},\n",
    "        {\"id\": 2, \"metric\": 110, \"timestamp\": \"2023-01-02\"},\n",
    "        {\"id\": 3, \"metric\": 120, \"timestamp\": \"2023-01-03\"},\n",
    "        {\"id\": 4, \"metric\": 115, \"timestamp\": \"2023-01-04\"},\n",
    "        {\"id\": 5, \"metric\": 125, \"timestamp\": \"2023-01-05\"},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM metrics\n",
    "    MATCH_RECOGNIZE (\n",
    "        ORDER BY timestamp\n",
    "        MEASURES \n",
    "            RUNNING AVG(A.metric) AS running_avg,\n",
    "            FINAL AVG(A.metric) AS final_avg,\n",
    "            RUNNING COUNT(*) AS running_count\n",
    "        ALL ROWS PER MATCH\n",
    "        PATTERN (A+)\n",
    "        DEFINE\n",
    "            A AS PREV(metric) IS NULL OR metric >= PREV(metric)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    result = match_recognize(query, df)\n",
    "    print(\"\\nRunning Measures Test:\")\n",
    "    print(result)\n",
    "\n",
    "def test_unmatched_rows():\n",
    "    \"\"\"Test handling of unmatched rows.\"\"\"\n",
    "    data = [\n",
    "        {\"id\": 1, \"value\": 100, \"category\": \"A\"},\n",
    "        {\"id\": 2, \"value\": 90, \"category\": \"B\"},\n",
    "        {\"id\": 3, \"value\": 80, \"category\": \"A\"},\n",
    "        {\"id\": 4, \"value\": 110, \"category\": \"B\"},\n",
    "        {\"id\": 5, \"value\": 120, \"category\": \"A\"},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM data\n",
    "    MATCH_RECOGNIZE (\n",
    "        PARTITION BY category\n",
    "        ORDER BY id\n",
    "        MEASURES \n",
    "            FIRST(A.value) AS start_value,\n",
    "            LAST(A.value) AS end_value\n",
    "        ALL ROWS PER MATCH WITH UNMATCHED ROWS\n",
    "        PATTERN (A+)\n",
    "        DEFINE\n",
    "            A AS PREV(value) IS NULL OR value > PREV(value)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    result = match_recognize(query, df)\n",
    "    print(\"\\nUnmatched Rows Test:\")\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run all tests\n",
    "    test_basic_pattern()\n",
    "    test_price_trend()\n",
    "    test_complex_pattern()\n",
    "    test_running_measures()\n",
    "    test_unmatched_rows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
