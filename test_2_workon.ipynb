{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70595e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.default.employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Validation query with ALL ROWS PER MATCH\n",
    "query = \"\"\"\n",
    "    SELECT * FROM memory.default.employees MATCH_RECOGNIZE (\n",
    "        PARTITION BY department, region\n",
    "        ORDER BY hire_date\n",
    "        MEASURES \n",
    "            salary AS current_salary,\n",
    "            RUNNING SUM(salary) AS running_sum,\n",
    "            MATCH_NUMBER() AS match_num\n",
    "        ALL ROWS PER MATCH\n",
    "        PATTERN (A+)\n",
    "        DEFINE A AS salary > 1000\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",     \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "]\n",
    "    \n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Validation query with ALL ROWS PER MATCH\n",
    "query = \"\"\"\n",
    "    SELECT * FROM memory.default.employees MATCH_RECOGNIZE (\n",
    "        PARTITION BY department, region\n",
    "        ORDER BY hire_date\n",
    "        MEASURES \n",
    "            salary AS current_salary,\n",
    "            RUNNING SUM(salary) AS running_sum,\n",
    "            MATCH_NUMBER() AS match_num\n",
    "        ALL ROWS PER MATCH\n",
    "        PATTERN (A*)\n",
    "        DEFINE A AS salary > 1000\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",     \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "]\n",
    "    \n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "# Use an absolute import for match_recognize.\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM memory.default.employees MATCH_RECOGNIZE (\n",
    "        PARTITION BY department, region\n",
    "        ORDER BY hire_date\n",
    "        MEASURES salary AS avg_salary\n",
    "        PATTERN (A+)\n",
    "        DEFINE A AS salary > 1000\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "data = [\n",
    "        {\"id\": 1, \"name\": \"Alice\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "        {\"id\": 2, \"name\": \"Bob\",     \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "        {\"id\": 4, \"name\": \"Diana\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "    ]\n",
    "    \n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Validation query with ALL ROWS PER MATCH\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM memory.default.employees \n",
    "MATCH_RECOGNIZE (\n",
    "  PARTITION BY department, region\n",
    "  ORDER BY hire_date\n",
    "  MEASURES \n",
    "    A.salary AS starting_salary,\n",
    "    LAST(C.salary) AS ending_salary,\n",
    "    MATCH_NUMBER() AS match_num\n",
    "  ONE ROW PER MATCH\n",
    "  AFTER MATCH SKIP PAST LAST ROW\n",
    "  PATTERN (A B+ C+)\n",
    "  DEFINE \n",
    "    A AS salary > 1000,\n",
    "    B AS salary < 1000,\n",
    "    C AS salary > 1000\n",
    ");\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",     \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "]\n",
    "    \n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM memory.default.employees  MATCH_RECOGNIZE(\n",
    "    PARTITION BY department, region\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        salary AS current_salary,\n",
    "        RUNNING SUM(salary) AS running_sum\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (A {- B+ -} C+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000,\n",
    "        B AS salary < 1000,\n",
    "        C AS salary > 1000\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6599a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Example query with comprehensive CLASSIFIER usage\n",
    "query = \"\"\"\n",
    "SELECT * FROM  memory.default.employees MATCH_RECOGNIZE(\n",
    "    PARTITION BY department, region\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        CLASSIFIER(A) AS is_a_var,\n",
    "        CLASSIFIER(C) AS is_c_var,\n",
    "        salary AS current_salary,\n",
    "        RUNNING SUM(salary) AS running_sum\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (A {- B+ -} C+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000,\n",
    "        B AS salary < 1000,\n",
    "        C AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "]\n",
    "\n",
    "\n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d02df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM  memory.default.employees MATCH_RECOGNIZE(\n",
    "    PARTITION BY department, region\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        CLASSIFIER(A) AS is_a_var,\n",
    "        CLASSIFIER(C) AS is_c_var,\n",
    "        salary AS current_salary,\n",
    "        RUNNING SUM(salary) AS running_sum\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (A {- B+ -} C+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000,\n",
    "        B AS salary < 1000,\n",
    "        C AS salary > 1000\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Example query with comprehensive CLASSIFIER usage\n",
    "query = \"\"\"\n",
    "SELECT * FROM memory.default.employees MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (^A+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "]\n",
    "\n",
    "\n",
    "output_df = match_recognize(query, pd.DataFrame(data))\n",
    "print(\"Match Recognize Output:\")\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0e9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f4fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecb4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d919e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Create test data with different departments to test partition behavior\n",
    "data = [\n",
    "    # Sales department - First row has high salary\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-01\", \"salary\": 1200},\n",
    "    {\"id\": 2, \"name\": \"Bob\",   \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-02\", \"salary\": 1300},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-03\", \"salary\": 900},\n",
    "    {\"id\": 4, \"name\": \"Diana\", \"department\": \"Sales\", \"region\": \"West\", \"hire_date\": \"2021-01-04\", \"salary\": 1100},\n",
    "    \n",
    "    # Marketing department - Last row has high salary\n",
    "    {\"id\": 5, \"name\": \"Eve\", \"department\": \"Marketing\", \"region\": \"East\", \"hire_date\": \"2021-01-01\", \"salary\": 900},\n",
    "    {\"id\": 6, \"name\": \"Frank\", \"department\": \"Marketing\", \"region\": \"East\", \"hire_date\": \"2021-01-02\", \"salary\": 950},\n",
    "    {\"id\": 7, \"name\": \"Grace\", \"department\": \"Marketing\", \"region\": \"East\", \"hire_date\": \"2021-01-03\", \"salary\": 980},\n",
    "    {\"id\": 8, \"name\": \"Henry\", \"department\": \"Marketing\", \"region\": \"East\", \"hire_date\": \"2021-01-04\", \"salary\": 1200},\n",
    "    \n",
    "    # IT department - All rows have high salary\n",
    "    {\"id\": 9, \"name\": \"Ivy\", \"department\": \"IT\", \"region\": \"North\", \"hire_date\": \"2021-01-01\", \"salary\": 1500},\n",
    "    {\"id\": 10, \"name\": \"Jack\", \"department\": \"IT\", \"region\": \"North\", \"hire_date\": \"2021-01-02\", \"salary\": 1600},\n",
    "    {\"id\": 11, \"name\": \"Kate\", \"department\": \"IT\", \"region\": \"North\", \"hire_date\": \"2021-01-03\", \"salary\": 1700},\n",
    "    {\"id\": 12, \"name\": \"Leo\", \"department\": \"IT\", \"region\": \"North\", \"hire_date\": \"2021-01-04\", \"salary\": 1800},\n",
    "    \n",
    "    # HR department - No rows have high salary\n",
    "    {\"id\": 13, \"name\": \"Mike\", \"department\": \"HR\", \"region\": \"South\", \"hire_date\": \"2021-01-01\", \"salary\": 950},\n",
    "    {\"id\": 14, \"name\": \"Nina\", \"department\": \"HR\", \"region\": \"South\", \"hire_date\": \"2021-01-02\", \"salary\": 980},\n",
    "    {\"id\": 15, \"name\": \"Oscar\", \"department\": \"HR\", \"region\": \"South\", \"hire_date\": \"2021-01-03\", \"salary\": 990},\n",
    "    {\"id\": 16, \"name\": \"Pam\", \"department\": \"HR\", \"region\": \"South\", \"hire_date\": \"2021-01-04\", \"salary\": 995},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Testing Pattern Anchors\\n\")\n",
    "\n",
    "# Test 1: Start anchor (^) - Should match patterns starting at the beginning of a partition\n",
    "query_start_anchor = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (^A+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 1: Start Anchor (^) - Should only match departments where first employee has salary > 1000\")\n",
    "output_df = match_recognize(query_start_anchor, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65305d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 2: End anchor ($) - Should match patterns ending at the end of a partition\n",
    "query_end_anchor = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (A+$)\n",
    "    DEFINE \n",
    "        A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 2: End Anchor ($) - Should only match departments where last employee has salary > 1000\")\n",
    "output_df = match_recognize(query_end_anchor, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcefd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Both anchors (^$) - Should match patterns spanning the entire partition\n",
    "query_both_anchors = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (^A+$)\n",
    "    DEFINE \n",
    "        A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 3: Both Anchors (^$) - Should only match departments where ALL employees have salary > 1000\")\n",
    "output_df = match_recognize(query_both_anchors, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835490a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 4: Start anchor with ALL ROWS PER MATCH to see the actual matched rows\n",
    "query_start_all_rows = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (^A+)\n",
    "    DEFINE \n",
    "        A AS salary > 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 4: Start Anchor (^) with ALL ROWS PER MATCH - Shows matched rows\")\n",
    "output_df = match_recognize(query_start_all_rows, df)\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PERMUTE functionality\n",
    "query_permute = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY department\n",
    "    ORDER BY hire_date\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B))\n",
    "    DEFINE \n",
    "        A AS salary > 1200,\n",
    "        B AS salary < 1000\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test PERMUTE - Should match both orderings of A and B\")\n",
    "output_df = match_recognize(query_permute, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9db599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207c73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025f006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d26211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next test\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2845aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Create test data with different permutation patterns\n",
    "data = [\n",
    "    # Sequence 1: Has A-B-C pattern\n",
    "    {\"id\": 1, \"seq\": 1, \"step\": 1, \"event_type\": \"start\", \"value\": 100},  # A\n",
    "    {\"id\": 2, \"seq\": 1, \"step\": 2, \"event_type\": \"middle\", \"value\": 200}, # B\n",
    "    {\"id\": 3, \"seq\": 1, \"step\": 3, \"event_type\": \"end\", \"value\": 300},    # C\n",
    "    \n",
    "    # Sequence 2: Has B-A-C pattern\n",
    "    {\"id\": 4, \"seq\": 2, \"step\": 1, \"event_type\": \"middle\", \"value\": 250}, # B\n",
    "    {\"id\": 5, \"seq\": 2, \"step\": 2, \"event_type\": \"start\", \"value\": 150},  # A\n",
    "    {\"id\": 6, \"seq\": 2, \"step\": 3, \"event_type\": \"end\", \"value\": 350},    # C\n",
    "    \n",
    "    # Sequence 3: Has A-C-B pattern\n",
    "    {\"id\": 7, \"seq\": 3, \"step\": 1, \"event_type\": \"start\", \"value\": 175},  # A\n",
    "    {\"id\": 8, \"seq\": 3, \"step\": 2, \"event_type\": \"end\", \"value\": 275},    # C\n",
    "    {\"id\": 9, \"seq\": 3, \"step\": 3, \"event_type\": \"middle\", \"value\": 375}, # B\n",
    "    \n",
    "    # Sequence 4: Has C-B-A pattern\n",
    "    {\"id\": 10, \"seq\": 4, \"step\": 1, \"event_type\": \"end\", \"value\": 225},   # C\n",
    "    {\"id\": 11, \"seq\": 4, \"step\": 2, \"event_type\": \"middle\", \"value\": 325}, # B\n",
    "    {\"id\": 12, \"seq\": 4, \"step\": 3, \"event_type\": \"start\", \"value\": 425},  # A\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Testing PERMUTE Patterns\\n\")\n",
    "\n",
    "# Test 1: Basic PERMUTE - Match any order of A, B, C\n",
    "query_basic_permute = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        A.value AS a_value,\n",
    "        B.value AS b_value,\n",
    "        C.value AS c_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 1: Basic PERMUTE - Should match all sequences with A, B, C in any order\")\n",
    "output_df = match_recognize(query_basic_permute, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbb0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0118cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50204f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 4: PERMUTE with Subset Variables\n",
    "query_permute_subset = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        X.value AS x_value,\n",
    "        Y.value AS y_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    SUBSET\n",
    "        X = (A, B),\n",
    "        Y = (B, C)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 4: PERMUTE with Subset Variables - Using subset groupings\")\n",
    "output_df = match_recognize(query_permute_subset, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743cb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20926186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: PERMUTE with Quantifier\n",
    "query_permute_quantifier = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        FIRST(A.value) AS first_a_value,\n",
    "        LAST(C.value) AS last_c_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C)+)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 2: PERMUTE with Quantifier - Should match one or more occurrences of permutations\")\n",
    "output_df = match_recognize(query_permute_quantifier, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: PERMUTE with ALL ROWS PER MATCH\n",
    "query_permute_all_rows = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        RUNNING LAST(A.value) AS running_a_value\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 3: PERMUTE with ALL ROWS PER MATCH - Shows all matched rows\")\n",
    "output_df = match_recognize(query_permute_all_rows, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df826a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 4: PERMUTE with Subset Variables\n",
    "query_permute_subset = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        X.value AS x_value,\n",
    "        Y.value AS y_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    SUBSET\n",
    "        X = (A, B),\n",
    "        Y = (B, C)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 4: PERMUTE with Subset Variables - Using subset groupings\")\n",
    "output_df = match_recognize(query_permute_subset, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -type f -name \"*.py\" | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0514a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 5: Nested PERMUTE patterns\n",
    "query_nested_permute = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        A.value AS a_value,\n",
    "        B.value AS b_value,\n",
    "        C.value AS c_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, PERMUTE(B, C)))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 5: Nested PERMUTE - Testing nested permutation patterns\")\n",
    "output_df = match_recognize(query_nested_permute, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: PERMUTE with Complex Conditions\n",
    "query_permute_complex = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        A.value AS start_value,\n",
    "        B.value AS middle_value,\n",
    "        C.value AS end_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start' AND A.value < NEXT(A.value),\n",
    "        B AS event_type = 'middle' AND B.value > PREV(B.value),\n",
    "        C AS event_type = 'end' AND C.value > FIRST(A.value)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 6: PERMUTE with Complex Conditions - Testing complex pattern definitions\")\n",
    "output_df = match_recognize(query_permute_complex, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test 7: PERMUTE with Edge Cases\n",
    "query_permute_edge_cases = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        A.value AS a_value,\n",
    "        LAST(B.value) AS last_b_value,\n",
    "        FIRST(C.value) AS first_c_value\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (PERMUTE(A, B?, C?))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Test 7: PERMUTE with Edge Cases - Testing optional elements\")\n",
    "output_df = match_recognize(query_permute_edge_cases, df)\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28253034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e1048e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:src.parser.match_recognize_extractor:Full statement text: SELECT * FROM memory.default.op2 MATCH_RECOGNIZE( PARTITION BY seq ORDER BY step MEASURES MATCH_NUMBER() AS match_num ONE ROW PER MATCH PATTERN (()) DEFINE A AS event_type = 'start' -- DEFINE is ignored since pattern is empty );\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=*, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='memory')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['seq'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='step', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='MATCH_NUMBER()', alias='match_num', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=True)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONEROWPERMATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONE ROW PER MATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='()', metadata={'variables': [], 'base_variables': [], 'empty_pattern': True, 'allows_any_variable': True})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition=\"event_type = 'start'\")])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': [], 'base_variables': [], 'empty_pattern': True, 'allows_any_variable': True}\n",
      "DEBUG:src.parser.match_recognize_extractor:Empty pattern detected in validate_identifiers - skipping validation\n",
      "DEBUG:src.parser.match_recognize_extractor:Empty pattern detected - skipping variable validation\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: MATCH_NUMBER()\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted SELECT clause: SelectClause(items=[SelectItem(expression=*, metadata={})])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted FROM clause: FromClause(table='memory')\n",
      "DEBUG:src.parser.match_recognize_extractor:Visiting PatternRecognition context\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted PARTITION BY: PartitionByClause(columns=['seq'])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ORDER BY: OrderByClause(sort_items=[SortItem(column='step', ordering='ASC', nulls_ordering=None)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MEASURES: MeasuresClause(measures=[Measure(expression='MATCH_NUMBER()', alias='match_num', metadata={'semantics': 'RUNNING'}, is_classifier=False, is_match_number=True)])\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONEROWPERMATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted ROWS PER MATCH: ONE ROW PER MATCH\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted Pattern: PatternClause(pattern='()', metadata={'variables': [], 'base_variables': [], 'empty_pattern': True, 'allows_any_variable': True})\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted DEFINE: DefineClause(definitions=[Define(variable='A', condition=\"event_type = 'start'\")])\n",
      "DEBUG:src.parser.match_recognize_extractor:Updated Pattern tokens: {'variables': [], 'base_variables': [], 'empty_pattern': True, 'allows_any_variable': True}\n",
      "DEBUG:src.parser.match_recognize_extractor:Empty pattern detected in validate_identifiers - skipping validation\n",
      "DEBUG:src.parser.match_recognize_extractor:Empty pattern detected - skipping variable validation\n",
      "DEBUG:src.parser.match_recognize_extractor:Validated function usage for measure: MATCH_NUMBER()\n",
      "DEBUG:src.parser.match_recognize_extractor:Extracted MATCH_RECOGNIZE clause via recursive search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PERMUTE with Subset Variables - Trino Compatibility\n",
      "\n",
      "PERMUTE with Subset Variables - Using last component variable that appears in match:\n",
      "Pattern value: '()'\n",
      "Empty pattern detected - allowing any variable definition\n",
      "Raw rows_per_match text: ONEROWPERMATCH\n",
      "Using rows_per_match mode: RowsPerMatch.ONE_ROW\n",
      "Measure semantics: {'match_num': 'FINAL'}\n",
      "Match config: rows_per_match=RowsPerMatch.ONE_ROW, all_rows=False\n",
      "Start state is accepting - pattern allows empty matches\n",
      "DFA state 0 has transitions for variables: []\n",
      "Built DFA with 1 states\n",
      "  State 0: Accept, Variables: None, Excluded: None, Transitions: \n",
      "Find matches with all_rows=False, show_empty=True, include_unmatched=False\n",
      "Starting match at index 0, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 0 - start state is accepting\n",
      "Testing row 0, data: {'id': 1, 'seq': 1, 'step': 1, 'event_type': 'start', 'value': 100}\n",
      "No valid transition from accepting state 0 at row 0\n",
      "No valid transition from state 0 at row 0\n",
      "Using empty match as fallback: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 1}\n",
      "Starting match at index 1, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 1 - start state is accepting\n",
      "Testing row 1, data: {'id': 2, 'seq': 1, 'step': 2, 'event_type': 'middle', 'value': 200}\n",
      "No valid transition from accepting state 0 at row 1\n",
      "No valid transition from state 0 at row 1\n",
      "Using empty match as fallback: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 2}\n",
      "Starting match at index 2, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 2 - start state is accepting\n",
      "Testing row 2, data: {'id': 3, 'seq': 1, 'step': 3, 'event_type': 'end', 'value': 300}\n",
      "No valid transition from accepting state 0 at row 2\n",
      "No valid transition from state 0 at row 2\n",
      "Using empty match as fallback: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 3}\n",
      "Find matches completed in 0.000159 seconds\n",
      "Start state is accepting - pattern allows empty matches\n",
      "DFA state 0 has transitions for variables: []\n",
      "Built DFA with 1 states\n",
      "  State 0: Accept, Variables: None, Excluded: None, Transitions: \n",
      "Find matches with all_rows=False, show_empty=True, include_unmatched=False\n",
      "Starting match at index 0, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 0 - start state is accepting\n",
      "Testing row 0, data: {'id': 4, 'seq': 2, 'step': 1, 'event_type': 'middle', 'value': 250}\n",
      "No valid transition from accepting state 0 at row 0\n",
      "No valid transition from state 0 at row 0\n",
      "Using empty match as fallback: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 1}\n",
      "Starting match at index 1, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 1 - start state is accepting\n",
      "Testing row 1, data: {'id': 5, 'seq': 2, 'step': 2, 'event_type': 'start', 'value': 150}\n",
      "No valid transition from accepting state 0 at row 1\n",
      "No valid transition from state 0 at row 1\n",
      "Using empty match as fallback: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 2}\n",
      "Starting match at index 2, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 2 - start state is accepting\n",
      "Testing row 2, data: {'id': 6, 'seq': 2, 'step': 3, 'event_type': 'end', 'value': 350}\n",
      "No valid transition from accepting state 0 at row 2\n",
      "No valid transition from state 0 at row 2\n",
      "Using empty match as fallback: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 3}\n",
      "Find matches completed in 0.000148 seconds\n",
      "Start state is accepting - pattern allows empty matches\n",
      "DFA state 0 has transitions for variables: []\n",
      "Built DFA with 1 states\n",
      "  State 0: Accept, Variables: None, Excluded: None, Transitions: \n",
      "Find matches with all_rows=False, show_empty=True, include_unmatched=False\n",
      "Starting match at index 0, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 0 - start state is accepting\n",
      "Testing row 0, data: {'id': 7, 'seq': 3, 'step': 1, 'event_type': 'start', 'value': 175}\n",
      "No valid transition from accepting state 0 at row 0\n",
      "No valid transition from state 0 at row 0\n",
      "Using empty match as fallback: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 1}\n",
      "Starting match at index 1, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 1 - start state is accepting\n",
      "Testing row 1, data: {'id': 8, 'seq': 3, 'step': 2, 'event_type': 'end', 'value': 275}\n",
      "No valid transition from accepting state 0 at row 1\n",
      "No valid transition from state 0 at row 1\n",
      "Using empty match as fallback: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 2}\n",
      "Starting match at index 2, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 2 - start state is accepting\n",
      "Testing row 2, data: {'id': 9, 'seq': 3, 'step': 3, 'event_type': 'middle', 'value': 375}\n",
      "No valid transition from accepting state 0 at row 2\n",
      "No valid transition from state 0 at row 2\n",
      "Using empty match as fallback: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 3}\n",
      "Find matches completed in 0.000142 seconds\n",
      "Start state is accepting - pattern allows empty matches\n",
      "DFA state 0 has transitions for variables: []\n",
      "Built DFA with 1 states\n",
      "  State 0: Accept, Variables: None, Excluded: None, Transitions: \n",
      "Find matches with all_rows=False, show_empty=True, include_unmatched=False\n",
      "Starting match at index 0, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 0 - start state is accepting\n",
      "Testing row 0, data: {'id': 10, 'seq': 4, 'step': 1, 'event_type': 'end', 'value': 225}\n",
      "No valid transition from accepting state 0 at row 0\n",
      "No valid transition from state 0 at row 0\n",
      "Using empty match as fallback: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 0, 'end': -1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 1}\n",
      "Starting match at index 1, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 1 - start state is accepting\n",
      "Testing row 1, data: {'id': 11, 'seq': 4, 'step': 2, 'event_type': 'middle', 'value': 325}\n",
      "No valid transition from accepting state 0 at row 1\n",
      "No valid transition from state 0 at row 1\n",
      "Using empty match as fallback: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 1, 'end': 0, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 2}\n",
      "Starting match at index 2, state: State 0 (Accept, Vars: None)\n",
      "Found potential empty match at index 2 - start state is accepting\n",
      "Testing row 2, data: {'id': 12, 'seq': 4, 'step': 3, 'event_type': 'start', 'value': 425}\n",
      "No valid transition from accepting state 0 at row 2\n",
      "No valid transition from state 0 at row 2\n",
      "Using empty match as fallback: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True}\n",
      "\n",
      "Processing match with ONE ROW PER MATCH:\n",
      "Match: {'start': 2, 'end': 1, 'variables': {}, 'state': 0, 'is_empty': True, 'match_number': 3}\n",
      "Find matches completed in 0.000142 seconds\n",
      "\n",
      "Match data:\n",
      "Match number: 1 (Partition: seq=1)\n",
      "Global indices - Start: 0, End: -1\n",
      "Local indices within partition - Start: 0, End: -1\n",
      "Variables: {}\n",
      "Match number: 2 (Partition: seq=1)\n",
      "Global indices - Start: 1, End: 0\n",
      "Local indices within partition - Start: 1, End: 0\n",
      "Variables: {}\n",
      "Match number: 3 (Partition: seq=1)\n",
      "Global indices - Start: 2, End: 1\n",
      "Local indices within partition - Start: 2, End: 1\n",
      "Variables: {}\n",
      "Match number: 1 (Partition: seq=2)\n",
      "Global indices - Start: 3, End: 2\n",
      "Local indices within partition - Start: 2, End: 1\n",
      "Variables: {}\n",
      "Match number: 2 (Partition: seq=2)\n",
      "Global indices - Start: 4, End: 3\n",
      "Local indices within partition - Start: 3, End: 2\n",
      "Variables: {}\n",
      "Match number: 3 (Partition: seq=2)\n",
      "Global indices - Start: 5, End: 4\n",
      "Local indices within partition - Start: 4, End: 3\n",
      "Variables: {}\n",
      "Match number: 1 (Partition: seq=3)\n",
      "Global indices - Start: 6, End: 5\n",
      "Local indices within partition - Start: 5, End: 4\n",
      "Variables: {}\n",
      "Match number: 2 (Partition: seq=3)\n",
      "Global indices - Start: 7, End: 6\n",
      "Local indices within partition - Start: 6, End: 5\n",
      "Variables: {}\n",
      "Match number: 3 (Partition: seq=3)\n",
      "Global indices - Start: 8, End: 7\n",
      "Local indices within partition - Start: 7, End: 6\n",
      "Variables: {}\n",
      "Match number: 1 (Partition: seq=4)\n",
      "Global indices - Start: 9, End: 8\n",
      "Local indices within partition - Start: 8, End: 7\n",
      "Variables: {}\n",
      "Match number: 2 (Partition: seq=4)\n",
      "Global indices - Start: 10, End: 9\n",
      "Local indices within partition - Start: 9, End: 8\n",
      "Variables: {}\n",
      "Match number: 3 (Partition: seq=4)\n",
      "Global indices - Start: 11, End: 10\n",
      "Local indices within partition - Start: 10, End: 9\n",
      "Variables: {}\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: -1\n",
      "Setting match_num to 1 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 0\n",
      "Setting match_num to 2 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 1\n",
      "Setting match_num to 3 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 2\n",
      "Setting match_num to 1 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 3\n",
      "Setting match_num to 2 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 4\n",
      "Setting match_num to 3 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 5\n",
      "Setting match_num to 1 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 6\n",
      "Setting match_num to 2 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 7\n",
      "Setting match_num to 3 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 8\n",
      "Setting match_num to 1 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 9\n",
      "Setting match_num to 2 from evaluator\n",
      "Evaluating expression: MATCH_NUMBER() with FINAL semantics\n",
      "Context variables: {}\n",
      "Number of rows: 12\n",
      "Current index: 10\n",
      "Setting match_num to 3 from evaluator\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pattern_var'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pattern_var'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     32\u001b[0m query_permute_subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mFROM memory.default.op2\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPERMUTE with Subset Variables - Using last component variable that appears in match:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m output_df \u001b[38;5;241m=\u001b[39m match_recognize(query_permute_subset, df)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_df)\n",
      "File \u001b[0;32m~/Desktop/llm/Row_match_recognize/src/executor/match_recognize.py:391\u001b[0m, in \u001b[0;36mmatch_recognize\u001b[0;34m(query, df)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m var_priority\u001b[38;5;241m.\u001b[39mget(pattern_var, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Add a temporary column for sorting\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_sort_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpattern_var\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_var_priority)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Sort by the temporary column and then by seq\u001b[39;00m\n\u001b[1;32m    394\u001b[0m result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_sort_key\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pattern_var'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Create test data for PERMUTE with subset variables\n",
    "data = [\n",
    "    # Sequence 1: Has A-B-C pattern\n",
    "    {\"id\": 1, \"seq\": 1, \"step\": 1, \"event_type\": \"start\", \"value\": 100},  # A\n",
    "    {\"id\": 2, \"seq\": 1, \"step\": 2, \"event_type\": \"middle\", \"value\": 200}, # B\n",
    "    {\"id\": 3, \"seq\": 1, \"step\": 3, \"event_type\": \"end\", \"value\": 300},    # C\n",
    "    \n",
    "    # Sequence 2: Has B-A-C pattern\n",
    "    {\"id\": 4, \"seq\": 2, \"step\": 1, \"event_type\": \"middle\", \"value\": 250}, # B\n",
    "    {\"id\": 5, \"seq\": 2, \"step\": 2, \"event_type\": \"start\", \"value\": 150},  # A\n",
    "    {\"id\": 6, \"seq\": 2, \"step\": 3, \"event_type\": \"end\", \"value\": 350},    # C\n",
    "    \n",
    "    # Sequence 3: Has A-C-B pattern\n",
    "    {\"id\": 7, \"seq\": 3, \"step\": 1, \"event_type\": \"start\", \"value\": 175},  # A\n",
    "    {\"id\": 8, \"seq\": 3, \"step\": 2, \"event_type\": \"end\", \"value\": 275},    # C\n",
    "    {\"id\": 9, \"seq\": 3, \"step\": 3, \"event_type\": \"middle\", \"value\": 375}, # B\n",
    "    \n",
    "    # Sequence 4: Has C-B-A pattern\n",
    "    {\"id\": 10, \"seq\": 4, \"step\": 1, \"event_type\": \"end\", \"value\": 225},   # C\n",
    "    {\"id\": 11, \"seq\": 4, \"step\": 2, \"event_type\": \"middle\", \"value\": 325}, # B\n",
    "    {\"id\": 12, \"seq\": 4, \"step\": 3, \"event_type\": \"start\", \"value\": 425},  # A\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Testing PERMUTE with Subset Variables - Trino Compatibility\\n\")\n",
    "\n",
    "# Test: PERMUTE with Subset Variables and Updated Processing Logic\n",
    "query_permute_subset = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        A.value AS start_value,\n",
    "        B.value AS middle_value,\n",
    "        C.value AS end_value\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (PERMUTE(A, B, C))\n",
    "    DEFINE \n",
    "        A AS event_type = 'start' AND A.value < NEXT(A.value),\n",
    "        B AS event_type = 'middle' AND B.value > PREV(B.value),\n",
    "        C AS event_type = 'end' AND C.value > FIRST(A.value)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"PERMUTE with Subset Variables - Using last component variable that appears in match:\")\n",
    "output_df = match_recognize(query_permute_subset, df)\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c67a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c2e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f77702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for SUBSET clause and union variables\n",
    "print(\"Test: SUBSET clause with union variables\")\n",
    "query_subset = \"\"\"\n",
    "SELECT * FROM memory.default.orders MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        FIRST(X.value) AS first_x_value,\n",
    "        LAST(X.value) AS last_x_value,\n",
    "        CLASSIFIER(X) AS x_classifier\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (A B C)\n",
    "    SUBSET X = (A, C)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_subset, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for empty pattern matching\n",
    "print(\"Test: Empty pattern matching with ()\")\n",
    "query_empty_pattern = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (())\n",
    "    DEFINE\n",
    "        A AS event_type = 'start'  -- DEFINE is ignored since pattern is empty\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_empty_pattern, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83662e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for RUNNING vs FINAL semantics\n",
    "print(\"Test: RUNNING vs FINAL semantics\")\n",
    "query_semantics = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        RUNNING SUM(value) AS running_sum,\n",
    "        FINAL SUM(value) AS final_sum,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (A B C)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_semantics, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for ALL ROWS PER MATCH WITH UNMATCHED ROWS\n",
    "print(\"Test: ALL ROWS PER MATCH WITH UNMATCHED ROWS\")\n",
    "query_unmatched = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ALL ROWS PER MATCH WITH UNMATCHED ROWS\n",
    "    PATTERN (A B)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start' AND step = 1,\n",
    "        B AS event_type = 'middle' AND step = 2\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_unmatched, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d47be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for Pattern Exclusion {- ... -}\n",
    "print(\"Test: Pattern Exclusion Syntax\")\n",
    "query_exclusion = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ALL ROWS PER MATCH\n",
    "    PATTERN (A {- B -} C)\n",
    "    DEFINE \n",
    "        A AS event_type = 'start',\n",
    "        B AS event_type = 'middle',\n",
    "        C AS event_type = 'end'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_exclusion, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for reluctant quantifiers\n",
    "print(\"Test: Reluctant Quantifiers\")\n",
    "query_reluctant = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num,\n",
    "        COUNT(A.*) AS a_count,\n",
    "        COUNT(B.*) AS b_count\n",
    "    ONE ROW PER MATCH\n",
    "    PATTERN (A+? B+)\n",
    "    DEFINE \n",
    "        A AS step <= 2,\n",
    "        B AS step > 1\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_reluctant, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.executor.match_recognize import match_recognize\n",
    "\n",
    "# Test for AFTER MATCH SKIP options\n",
    "print(\"Test: AFTER MATCH SKIP options\")\n",
    "query_skip = \"\"\"\n",
    "SELECT * FROM memory.default.op2 MATCH_RECOGNIZE(\n",
    "    PARTITION BY seq\n",
    "    ORDER BY step\n",
    "    MEASURES \n",
    "        CLASSIFIER() AS pattern_var,\n",
    "        MATCH_NUMBER() AS match_num\n",
    "    ONE ROW PER MATCH\n",
    "    AFTER MATCH SKIP TO NEXT ROW\n",
    "    PATTERN (A B+)\n",
    "    DEFINE \n",
    "        A AS step = 1,\n",
    "        B AS step > 1\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "output_df = match_recognize(query_skip, df)\n",
    "print(output_df)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
